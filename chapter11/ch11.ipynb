{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN8V4WviLD8K"
      },
      "source": [
        "# Progressive Growing GAN\n",
        "\n",
        "A generative model in the GAN architecture learns to map points in a latent space to generated images. Latent space only has meaning as it applies to the generative model being trained. Yet, latent space has structure such as interpolation between points and vector arithmetic between points in its space to derive meaningful and targeted effects on generated images.\n",
        "\n",
        "GANs are effective at generating crisp synthetic images, but are limited in the size of the images that can be generated such 64 × 64 pixels. The **Progressive Growing GAN** is an extension to the GAN that enables training generator models to generate large high-quality images such as photorealistic faces with size 1024 × 1024 pixels.\n",
        "\n",
        "The key innovation of the Progressive Growing GAN is the incremental increase in the size of images output by the generator. By generating small images at the beginning of training and gradually adding convolutional layers to both the generator and discriminator to produce larger and larger images. For instance, starting with 4 × 4 pixel images, doubling to 8 × 8, 16 × 16, and so on until the desired output resolution is reached. the desired output size is met.\n",
        "\n",
        "Resource for GAN tutorials:\n",
        "\n",
        "https://www.tensorflow.org/hub/tutorials\n",
        "\n",
        "Resource for Progressive Growing GAN:\n",
        "\n",
        "https://www.tensorflow.org/hub/tutorials/tf_hub_generative_image_module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nj5Q693Ueg0"
      },
      "source": [
        "# Vector Arithmetic in Latent Space\n",
        "\n",
        "The generator model in the GAN architecture takes a point from the latent space as input and generates a new image. Typically, latent space is a 100-dimensional hypersphere with each variable drawn from a Gaussian distribution with mean of zero and a standard deviation of one. During training, the generator learns how to map points into the latent space with specific output images and this mapping is different each time the model is trained.\n",
        "\n",
        "The latent space has structure when interpreted by the generator model and this structure can be queried and navigated for a given model. Typically, new images are generated using random points in the latent space. However, latent space can be constructed (e.g. all 0s, all 0.5s, or all 1s) and used as input or a query to generate a specific image. Points in the latent space can be kept and used in simple vector arithmetic to create new points in the latent space, which can be used to generate images.\n",
        "\n",
        "A series of points can be created on a linear path between two points in the latent space such as two generated images. The series of points can be used to generate a series of images that show a transition between the two generated images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcSflKHgT4Pn"
      },
      "source": [
        "# Import **tensorflow** library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-ti_NZ48cx-"
      },
      "source": [
        "Import library and alias it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrMaI2gUT4tN"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hg87Y5yK_D6"
      },
      "source": [
        "# GPU Hardware Accelerator\n",
        "\n",
        "To vastly speed up processing, we can use the GPU available from the Google Colab cloud service. Colab provides a free Tesla K80 GPU of about 12 GB. It’s very easy to enable the GPU in a Colab notebook:\n",
        "\n",
        "1.\tclick **Runtime** in the top left menu\n",
        "2.\tclick **Change runtime** type from the drop-down menu\n",
        "3.\tchoose **GPU** from the Hardware accelerator drop-down menu\n",
        "4.\tclick **SAVE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2jeC-Di9nxP"
      },
      "source": [
        "Verify that GPU is available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rkO7rkO2tTN"
      },
      "source": [
        "tf.__version__, tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgKQLsRZW4Tc"
      },
      "source": [
        "# Install Packages for Creating Animations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAmyQS4A8iXm"
      },
      "source": [
        "We need to install **imageio**, **scikit-image**, and **tensorflow-docs**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d60uzOPr219f"
      },
      "source": [
        "!pip -q install imageio\n",
        "!pip -q install scikit-image\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CABkGKxqXcoE"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hZrgZq5XA9c"
      },
      "source": [
        "Abseil Python is a logging module implemented on top of standard logging:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlrOhzyDXBVL"
      },
      "source": [
        "from absl import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHN1GcKiXkJc"
      },
      "source": [
        "Install libraries for image processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayL-TjS1-S8W"
      },
      "source": [
        "import imageio\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from skimage import transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov8diBqPX2fO"
      },
      "source": [
        "The **imageio** package is a Python library that provides an easy interface to read and write a wide range of image data, including animated images, volumetric data, and scientific formats. The **Image** module is used to represent a PIL image. The **plt** module is used for displaying images. The **display** module is a public API for display tools in IPython. The **transform** module is used for image processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyUN59yhYl2s"
      },
      "source": [
        "Import other libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohu0bHYcYl8r"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN_BSO8rZuVH"
      },
      "source": [
        "The **hub** module allows access to TensorFlow Hub, which is a repository of trained machine learning models. The **embed** module is used to embed animation in a notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4NmM5WFZp2O"
      },
      "source": [
        "# Generate a Global Random Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRTvv7jv9txo"
      },
      "source": [
        "Set a global random seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD17fPDeZnae"
      },
      "source": [
        "tf.random.set_seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wkF3k2r7JEX"
      },
      "source": [
        "Seed value does not have to be the number we set. Seed values can be set to any number. For reproducibility, use the same seed when comparing experiments!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylsyajWqbaJR"
      },
      "source": [
        "# Set Dimensions for Latent Spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1y6bzJr-gzD"
      },
      "source": [
        "**Latent space** is a compressed representation of a dataset (of observations or events) where similar data points are closer together in space. For instance, two images of dogs are closer together in space than an image of a dog and one of a tree.\n",
        "\n",
        "Latent space is useful for learning data features and finding simpler representations of data for analysis. As humans, we have an understanding of a broad range of topics and the events belonging to those topics. Latent space aims to provide a similar understanding for a computer model through a quantitative spatial representation.\n",
        "\n",
        "Compressing a dataset into a latent space helps a model better understand the observed data because the model deals with much smaller variations than it would with the entire dataset. That is, the model deals with a smaller space than it would without compressing the dataset into a latent space.\n",
        "\n",
        "The terms *high dimensional* and *low dimensional* help us define how specific or how general the kinds of features we want our latent space to learn and represent. High dimensional latent space is sensitive to more specific features of the input data and can sometimes lead to overfitting when there isn't sufficient training data. Low dimensional latent space aims to capture the most important features (or aspects) required to learn and represent the input data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wb8UAqnDngV"
      },
      "source": [
        "We set a high dimensional latent space of 512 because the pre-trained model we use for this experiment learned on this latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQGJjU3lbaOp"
      },
      "source": [
        "latent_dim = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuTOgAlVbbI_"
      },
      "source": [
        "The pre-trained model we use maps from a 512-dimensional latent space to images. We can retrieve this value from **module.structured_input_signature** if we don't know beforehand the module we are using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLlXPjv9c-YY"
      },
      "source": [
        "# Create Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI5RcXmjcB0M"
      },
      "source": [
        "## Create a Function to Interpolate Hypershpere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "239sa6XCEN4f"
      },
      "source": [
        "The function finds the space between vectors in space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDKEfoJscPJv"
      },
      "source": [
        "def interpolate_hypersphere(v1, v2, num_steps):\n",
        "  v1_norm = tf.norm(v1)\n",
        "  v2_norm = tf.norm(v2)\n",
        "  v2_normalized = v2 * (v1_norm / v2_norm)\n",
        "  vectors = []\n",
        "  for step in range(num_steps):\n",
        "    interpolated =\\\n",
        "      v1 + (v2_normalized - v1) *\\\n",
        "      step / (num_steps - 1)\n",
        "    interpolated_norm = tf.norm(interpolated)\n",
        "    interpolated_normalized =\\\n",
        "      interpolated * (v1_norm / interpolated_norm)\n",
        "    vectors.append(interpolated_normalized)\n",
        "  return tf.stack(vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzKIvb15cPOE"
      },
      "source": [
        "The function initiates latent space interpolation between two randomly initialized vectors. It interpolates between vectors that are non-zero and don't both lie on a line going through the origin and returns the normalized interpolated vectors to the calling environment.\n",
        "\n",
        "The function begins by creating two Euclidean normed vectors v1 and v2. It then normalizes v2 to have the same norm as v1. It continues by interpolating between the two vectors on the hypersphere (or latent space) to produce a set of vectors based on the number of interpolation steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt3WLxHxcnsY"
      },
      "source": [
        "## Create Functions to Display an Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GsPvve1EaQd"
      },
      "source": [
        "The first function displays an image using the **PIL** library. The seond function displays an image using *imshow*. from **pyplot**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwATTHizcnyn"
      },
      "source": [
        "def display_image(image):\n",
        "  image = tf.constant(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "  return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "def show_image(image):\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNfU2VT2dJaB"
      },
      "source": [
        "##Create a Function to Show Animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oItOCNuYE8L-"
      },
      "source": [
        "The function uses **imageio** to display animation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NR-msJ8dRsJ"
      },
      "source": [
        "def animate(images):\n",
        "  images = np.array(images)\n",
        "  converted_images = np.clip(\n",
        "      images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images)\n",
        "  return embed.embed_file('./animation.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKm0_XN5dVr_"
      },
      "source": [
        "Given a set of images, show an animation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUaowVoAdR3Y"
      },
      "source": [
        "# Set Verbosity for Error Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idImFkd2FNVW"
      },
      "source": [
        "We just want to see logging errors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuxBSnO1YmAT"
      },
      "source": [
        "logging.set_verbosity(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcoNvrUPj4I3"
      },
      "source": [
        "# Progressive GAN Experiment\n",
        "\n",
        "We use the progan-128 pre-trained model to generate realistic celebrity images. The **progan-128** model is a Progressive GAN trained on CelebA for 128x128 images. It maps from a 512-dimensional latent space to images. During training, the latent space vectors are sampled from a normal distribution.\n",
        "\n",
        "The module takes a tensor (Tensor(tf.float32, shape=[?, 512]) that represents a batch of latent vectors as input and outputs a tensor (Tensor(tf.float32, shape=[?, 128, 128, 3]) that represents a batch of RGB images. The original model is trained on a GPU for 636,801 steps with a batch size 16.\n",
        "\n",
        "CelebA (CelebFaces Attributes Dataset) is a large-scale face attributes dataset containing more than 200,000 celebrity images. Each image has 40 attribute annotations. Images in this dataset cover large pose variations and background clutter. CelebA also has large diversities, large quantities, and rich annotations including:\n",
        "\n",
        "* 10,177 number of identities\n",
        "* 202,599 number of face images\n",
        "* 5 landmark locations\n",
        "* 40 binary attributes annotations per image\n",
        "\n",
        "CelebA can be employed as the training and test sets for the following computer vision tasks: face attribute recognition, face detection, landmark (or facial part) localization, and face editing & synthesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC0djK8Ddroz"
      },
      "source": [
        "## Load the Pre-Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmwMZGWrGLDy"
      },
      "source": [
        "Load the **progran-128** pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5BGq0gt-S-s"
      },
      "source": [
        "hub_model = hub.load(\n",
        "    'https://tfhub.dev/google/progan-128/1')\\\n",
        "    .signatures['default']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9p7UclwJoBS"
      },
      "source": [
        "To find the progran-128 site, peruse:\n",
        "\n",
        "https://tfhub.dev/google/progan-128/1\n",
        "\n",
        "To find all models currently hosted on tfhub.dev that can generate images, peruse:\n",
        "\n",
        "https://tfhub.dev/s?module-type=image-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8odDlNW2l-H"
      },
      "source": [
        "Get output shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2TaRqKc1KGl"
      },
      "source": [
        "hub_model.output_shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLkq1_Ww3k-6"
      },
      "source": [
        "Get dimensions for latent spaces (latent vector):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzXQabYz27hQ"
      },
      "source": [
        "hub_model.structured_input_signature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0kWOBcCGi5r"
      },
      "source": [
        "We just verified that CelebA uses 512 dimensional latent space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSm9nQsRm54b"
      },
      "source": [
        "## Generate and Display an Image\n",
        "\n",
        "New images are generated using random points in the latent space. The pre-trained model identifies the closest vector in the latent space and generates an image from that vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb6D60SAnlKd"
      },
      "source": [
        "Create a function to find the closest vector in the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcNzTzum1UT"
      },
      "source": [
        "def get_module_space_image():\n",
        "  vector = tf.random.normal([1, latent_dim])\n",
        "  image = hub_model(vector)['default'][0]\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mosq6d-m1L0"
      },
      "source": [
        "The function creates a random vector between 1 and 512. It then uses the pretrained model to generate an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilUmh410nP3N"
      },
      "source": [
        "Display the generated image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIw9nfgsnQDb"
      },
      "source": [
        "generated_image = get_module_space_image()\n",
        "display_image(generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXU3Hgqionze"
      },
      "source": [
        "Not bad! The pre-trained model generates relatively realistic images from the latent space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3BXcufEdz8K"
      },
      "source": [
        "## Create a Function to Generate Multiple Images from Latent Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hoRjhJ-G1vG"
      },
      "source": [
        "The function creates two random vectors, interpolates the space between them, and uses the pre-trained model to generate images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhSdk9zk-p-9"
      },
      "source": [
        "def interpolate_between_vectors(steps):\n",
        "  v1 = tf.random.normal([latent_dim])\n",
        "  v2 = tf.random.normal([latent_dim])\n",
        "  # creates a tensor with n steps of interpolation between v1 and v2.\n",
        "  vectors = interpolate_hypersphere(v1, v2, steps)\n",
        "  # use module to generate images from the latent space.\n",
        "  interpolated_images = hub_model(vectors)['default']\n",
        "  return interpolated_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z_rQDAZCrxn"
      },
      "source": [
        "The function creates two random vectors based on the latent space of 512 dimensions. It then creates a set of vectors from the latent space. It continues by leveraging the trained model on the set of vectors to create a set of new interpolated images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARYUYzn-eHM0"
      },
      "source": [
        "## Display an Animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv1SMxWlHD8h"
      },
      "source": [
        "Let's create an animation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2p_hRLbeHSK"
      },
      "source": [
        "interpolation_steps = 100\n",
        "interpolated_images = interpolate_between_vectors(\n",
        "    interpolation_steps)\n",
        "animate(interpolated_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvRJp-9CHKHe"
      },
      "source": [
        "Pretty amazing! With the help of our pretrained model, we create an animation from two random vectors.\n",
        "\n",
        "The number of steps makes a big difference in the shaping process! The higher the number of steps, the more interpolated images are created between the random vectors in the latent space. So experiment with the number of steps to see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMA4BEWfjgIf"
      },
      "source": [
        "## Display Interpolated Image Vectors\n",
        "\n",
        "Display each interpolated image to monitor the image generation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTv48MpUXwNX"
      },
      "source": [
        "Get the number of interpolated images between random vectors v1 and v2 in the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cydEvpOyXwTu"
      },
      "source": [
        "num_imgs = len(interpolated_images)\n",
        "num_imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQez3-7FlOhY"
      },
      "source": [
        "Show the initial image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4-9S90PlOnp"
      },
      "source": [
        "show_image(interpolated_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dux59V7lkynx"
      },
      "source": [
        "Show the final image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mPWV00UZzIz"
      },
      "source": [
        "show_image(interpolated_images[num_imgs - 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJdRQF0PlG1q"
      },
      "source": [
        "So the process begins with the initial image and morphs it into the final image!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjCzBbJ0YWjq"
      },
      "source": [
        "Create a function to display generated image vectors from the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULqeGHsFeEjA"
      },
      "source": [
        "def generated_images(images, cols, rows):\n",
        "  columns, rows = cols, rows\n",
        "  ax = []\n",
        "  fig = plt.figure(figsize=(20, 20))\n",
        "  for i in range(columns*rows):\n",
        "    img = images[i].numpy()\n",
        "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QyFN3acy9wV"
      },
      "source": [
        "Display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba_H9MgVy93a"
      },
      "source": [
        "generated_images(interpolated_images, 10, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANi-IeSJl8Zz"
      },
      "source": [
        "Its' fascinating to see how the model is able to morph images as it interpolates vectors from the latent space!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1yZO29giTM3"
      },
      "source": [
        "## Interpolate a Vector from an Uploaded Image\n",
        "\n",
        "We can generate a random vector from the latent space or or upload our own image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT0W0CFevsg7"
      },
      "source": [
        "Import requisite library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBIgsN-dvsoF"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hde8hHlywqmA"
      },
      "source": [
        "Resource:\n",
        "\n",
        "https://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE0WyzkpigXW"
      },
      "source": [
        "Create function to get an uploaded image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64J-_jfVhl9e"
      },
      "source": [
        "def upload_image():\n",
        "  uploaded = files.upload()\n",
        "  image = imageio.imread(uploaded[list(uploaded.keys())[0]])\n",
        "  return transform.resize(image, [128, 128])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og3l6vcgilGr"
      },
      "source": [
        "Get image from your local drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3yoWm_IilgI"
      },
      "source": [
        "local_image = upload_image()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWwqVGeoufCe"
      },
      "source": [
        "Click **Choose Files** to select the image you want to load from your local drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHIgQ8fv1sH"
      },
      "source": [
        "Display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mxFrPf-t42W"
      },
      "source": [
        "display_image(local_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "freImPwne8Pz"
      },
      "source": [
        "Create a generated image based on the local image vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Dh2U-1dlVu"
      },
      "source": [
        "vector = tf.dtypes.cast(local_image, tf.float32)\n",
        "generated_image = hub_model(vector)['default'][0]\n",
        "display_image(generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgeDqxNU2x3H"
      },
      "source": [
        "Instead of creating a latent vector, create one from an uploaded image tensor. We do need to convert the local image tensor to a float tensor. Continue by generating an image from the float tensor with the help of progran-128. End by displaying the image. The program-128 model generates a new image based on what it learned from CelebA. So the generated image resembles a human face regardless of what image is uploaded because progran-128 learned on human faces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J13L523ejsqy"
      },
      "source": [
        "# Show Multiple Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMePJOVWoWll"
      },
      "source": [
        "Create a function to return a latent vector and image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYCncacL0L1z"
      },
      "source": [
        "def get_vector():\n",
        "  vector = tf.random.normal([1, latent_dim])\n",
        "  image = hub_model(vector)['default'][0]\n",
        "  return vector, image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lJTWzV93iPI"
      },
      "source": [
        "Display images from latent vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HybNWWP3iWZ"
      },
      "source": [
        "for _ in range(2):\n",
        "  latent_vector, image = get_vector()\n",
        "  print (latent_vector[0][0:3])\n",
        "  show_image(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9u_48CDsT40"
      },
      "source": [
        "The function returns a vector from the latent space and an is image generated from program-128. Each time the function is executed, images are different because each vector is generated randomly from the latent space, fed into program-128, and generated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOqc6Jz_oZex"
      },
      "source": [
        "Subplot display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Io4hhRZzxI7"
      },
      "source": [
        "rows, cols = 2, 2\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(rows*cols):\n",
        "  plt.subplot(rows, cols, i + 1)\n",
        "  plt.imshow(get_module_space_image())\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtuLepQtDtrx"
      },
      "source": [
        "Sometimes images are more realistic than other times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw_Mx7s2ocRq"
      },
      "source": [
        "# Find Closest Latent Vector Experiment\n",
        "\n",
        "Fix a target image to find the closest latent vector. Use an image generated from the model or upload your own.\n",
        "\n",
        "For an excellent resource for automating image generation, peruse:\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf_hub_generative_image_module.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADoxLq-eqlvG"
      },
      "source": [
        "## Set Initial Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdUBTPP0Ky2w"
      },
      "source": [
        "Generate a seed for reproducibility and set initial vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liNZ8AxnJTU-"
      },
      "source": [
        "seed_value = 777\n",
        "tf.random.set_seed(seed_value)\n",
        "feature_vector = tf.random.normal([1, latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc6JktW6PIqT"
      },
      "source": [
        "Verify that the feature vector was drawn from the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqmMK8BtPEkt"
      },
      "source": [
        "feature_vector.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLLLkk--RBcF"
      },
      "source": [
        "The feature vector is drawn from the 512-dimensional latent space as indicated by shape 1 x 512. So the vector is a 1-dimensional vector with 512 pixel elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kvQMsGBEF1C"
      },
      "source": [
        "Change the seed to generate a different image. Be careful to use the same seeds for reproducibility between experiements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19TKOAPxrBOA"
      },
      "source": [
        "### Display Image from Initial Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTmjSpY1K8Oo"
      },
      "source": [
        "Display an image from the random vector using the pretrained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYlfbboP_WAd"
      },
      "source": [
        "display_image(hub_model(feature_vector)['default'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5r1KtpuM1YW"
      },
      "source": [
        "## Create a New Target Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqIvNutaM6Ls"
      },
      "source": [
        "Let's create a new target image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyh4f8z9MnVp"
      },
      "source": [
        "target_image = get_module_space_image()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50DC2EEhM_MH"
      },
      "source": [
        "Verify shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qWoIwfpMPlF"
      },
      "source": [
        "target_image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmNM4tlxxYy7"
      },
      "source": [
        "Display new target image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih3yK_EFxY5r"
      },
      "source": [
        "display_image(target_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ2WppGOrrOI"
      },
      "source": [
        "## Create Function to Find Closest Latent Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYHlhh8eLPk7"
      },
      "source": [
        "Define a loss function between the target image and the image generated by a latent space variable. Next, use gradient descent to find variable values that minimize the loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F2zpUhtLGN9"
      },
      "source": [
        "def find_closest_latent_vector(\n",
        "    initial_vector, target_image,\n",
        "    num_optimization_steps,\n",
        "    steps_per_image, loss_alg):\n",
        "  images = []\n",
        "  losses = []\n",
        "  vector = tf.Variable(initial_vector)\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "  loss_fn = loss_alg\n",
        "  for step in range(num_optimization_steps):\n",
        "    if (step % 100)==0:\n",
        "      print()\n",
        "    print('.', end='')\n",
        "    with tf.GradientTape() as tape:\n",
        "      image = hub_model(vector.read_value())['default'][0]\n",
        "      if (step % steps_per_image) == 0:\n",
        "        images.append(image.numpy())\n",
        "      target_image_difference = loss_fn(\n",
        "          image, target_image[:,:,:3])\n",
        "      # The latent vectors were sampled from a normal distribution. We can get\n",
        "      # more realistic images if we regularize the length of the latent vector\n",
        "      # to the average length of vector from this distribution.\n",
        "      regularizer = tf.abs(tf.norm(vector) - np.sqrt(latent_dim))\n",
        "      loss = target_image_difference + regularizer\n",
        "      losses.append(loss.numpy())\n",
        "    grads = tape.gradient(loss, [vector])\n",
        "    optimizer.apply_gradients(zip(grads, [vector]))\n",
        "  return images, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_aZk_gHLeec"
      },
      "source": [
        "The function accepts the initial vector we just created, number of steps, steps per image, and the loss algorithm. It then initializes variables including the initial vector, optimizer, and loss function. The function continues by training for the number of steps. The training loop uses the pre-trained model to generate an image, finds the space between the image we just created and the target image, uses regularization to get more realistic images, calculates loss, applies the gradient descent algorithm, and optimizes the gradients. Once training is completed, the function returns an array of images generated and an array of losses calculated during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ReBJhoyRJQH"
      },
      "source": [
        "Create the loss algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeWbED2wRJWx"
      },
      "source": [
        "reduction = tf.keras.losses.Reduction.SUM\n",
        "mae_loss_algorithm = tf.losses.MeanAbsoluteError(reduction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNEOamYQRidQ"
      },
      "source": [
        "Generally, the tf.losses.MeanAbsoluteError API computes the mean of absolute difference between labels and predictions. In our experiment, it computes the mean absolute difference between vectors in latent space and corresponding actual targets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlhPqFhFrK2U"
      },
      "source": [
        "Clear previous sessions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9qrnxMyrLCe"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1A1yt0SsRPQ"
      },
      "source": [
        "Run the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9agq5obJNEM8"
      },
      "source": [
        "num_optimization_steps = 200\n",
        "steps_per_image = 5\n",
        "mae_images, mae_loss = find_closest_latent_vector(\n",
        "    feature_vector, target_image, num_optimization_steps,\n",
        "    steps_per_image, mae_loss_algorithm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bJGih4gNKYY"
      },
      "source": [
        "Tweak optimization steps and steps per image to see the impact on the visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poIoiKYc0JSM"
      },
      "source": [
        "## Plot Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3eBmvkxLZLT"
      },
      "source": [
        "Plot loss performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icxXV1yj_Tjd"
      },
      "source": [
        "plt.plot(mae_loss)\n",
        "fig = plt.ylim([0, max(plt.ylim())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foBialDhUvVd"
      },
      "source": [
        "Calculate final loss for MAE reduction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr_MDP5_UvcX"
      },
      "source": [
        "MAE_loss = mae_loss[num_optimization_steps - 1]\n",
        "MAE_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5qgJKE10T8M"
      },
      "source": [
        "## Animate Generated Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Ppfeb4NEIs"
      },
      "source": [
        "Create an animation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENSeKKKK_fIu"
      },
      "source": [
        "animate(np.stack(mae_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph1fpO0k0ZoE"
      },
      "source": [
        "## Compare the Result to the Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlAu-fWKOSTA"
      },
      "source": [
        "Get number of images generated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oih8kKWBOC95"
      },
      "source": [
        "len(mae_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20AwG6o70QpO"
      },
      "source": [
        "Get image type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDX5btSQ0Qum"
      },
      "source": [
        "type(mae_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJxksSG75gwB"
      },
      "source": [
        "Create a function to display images generated from the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpoU3dGc2fSF"
      },
      "source": [
        "def closest_latent_images(faces, rows, cols):\n",
        "  fig = plt.figure(1, (20., 40.))\n",
        "  for i in range(40):\n",
        "    plt.subplot(10, 4, i+1)\n",
        "    plt.imshow(faces[i])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg8zAzLG6XNj"
      },
      "source": [
        "Display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtBWCtLz6XdF"
      },
      "source": [
        "closest_latent_images(mae_images, 10, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFqhq0K-X1M_"
      },
      "source": [
        "During each step of the training loop, the function generates a new image from by leveraging the pre-trained weights from the progan-128. It then compares the new image to the target. Gradually, through gradient descent and loss minimization techniques images become more and more similar to the target. It's magic!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBbNCdN5xmFl"
      },
      "source": [
        "Contrast the first generated image against the target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6TGZ1bGxmMa"
      },
      "source": [
        "display_image(np.concatenate(\n",
        "    [mae_images[0], target_image], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlzoINbdNTLd"
      },
      "source": [
        "Show how well the model performs by showing final generated image with target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvWrsAYA_iP2"
      },
      "source": [
        "display_image(np.concatenate(\n",
        "    [mae_images[-1], target_image], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuZRyyf6XECA"
      },
      "source": [
        "Grab 'mae_images\\[-1]' to display the final generated image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjTMkSh4PALD"
      },
      "source": [
        "Use other display function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNmX3W6JPARj"
      },
      "source": [
        "show_image(np.concatenate(\n",
        "    [mae_images[-1], target_image], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_EXLTIfNXuV"
      },
      "source": [
        "Not bad at all!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzLtPNw2UXj3"
      },
      "source": [
        "## Try a Different Loss Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqAsRVnaTl_Q"
      },
      "source": [
        "Use a MSE instead of MAE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-7Ht1GpTmFJ"
      },
      "source": [
        "reduction = tf.keras.losses.Reduction.SUM\n",
        "mse_loss_algorithm = tf.losses.MeanSquaredError(reduction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htHf3R8nuS3L"
      },
      "source": [
        "Clear previous models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GgFkfpiuSCs"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hx_iRiFTmLF"
      },
      "source": [
        "Generate images from latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ain4IkN8TmTE"
      },
      "source": [
        "num_optimization_steps = 200\n",
        "steps_per_image = 5\n",
        "mse_images, mse_loss = find_closest_latent_vector(\n",
        "    feature_vector, target_image, num_optimization_steps,\n",
        "    steps_per_image, mse_loss_algorithm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haLidUlvTmYQ"
      },
      "source": [
        "Plot loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnawFaYATmds"
      },
      "source": [
        "plt.plot(mse_loss)\n",
        "fig = plt.ylim([0, max(plt.ylim())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RHTWpTPU2pR"
      },
      "source": [
        "Calculate final lose for MSE reduction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaxmswGGU2vz"
      },
      "source": [
        "MSE_loss = mse_loss[num_optimization_steps - 1]\n",
        "MSE_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyShDybLWIHN"
      },
      "source": [
        "MSE reduction appears to be much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dONx3e7dULRb"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiY1pJPiULYf"
      },
      "source": [
        "animate(np.stack(mse_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Dr5fZKWNLp"
      },
      "source": [
        "Compare final generated image with the actual target image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_amjVfsWNSb"
      },
      "source": [
        "display_image(np.concatenate(\n",
        "    [mse_images[-1], target_image], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrBjWbJ2dMkf"
      },
      "source": [
        "Display the MAE comparison:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0fN6Z1sdMtf"
      },
      "source": [
        "display_image(np.concatenate(\n",
        "    [mae_images[-1], target_image], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csa7YMmaC9jZ"
      },
      "source": [
        "## Create a Target from an Uploaded Image\n",
        "\n",
        "Instead of creating a target image with progran-128 from a random vector in the latent space, create a latent vector from an uploaded image and use progran-128 to create a target image from the latent space. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lwJSd6bDCtX"
      },
      "source": [
        "Create an initial feature vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYG3ZwrKDC5j"
      },
      "source": [
        "seed_value = 0\n",
        "tf.random.set_seed(seed_value)\n",
        "feature_vector = tf.random.normal([1, latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzI9MInLDDBs"
      },
      "source": [
        "Grab an image from a local drive and display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUdVk1NjDDI_"
      },
      "source": [
        "uploaded_image = upload_image()\n",
        "display_image(uploaded_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWn3jLRqnMrR"
      },
      "source": [
        "Get shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNv3KCG7nIVS"
      },
      "source": [
        "uploaded_image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyhV50ZJsnOy"
      },
      "source": [
        "Convert uploaded image to float32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0DwTYbysnWd"
      },
      "source": [
        "uploaded_vector = tf.dtypes.cast(uploaded_image, tf.float32)\n",
        "display_image(uploaded_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-L_XW2Ds6je"
      },
      "source": [
        "The vector is not the target image because it was not drawn from the latent space. Use progran-128 to generate the target image from a vector in the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XViK2j4tDDsA"
      },
      "source": [
        "uploaded_target = hub_model(uploaded_vector)['default'][0]\n",
        "display_image(uploaded_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdNbaZ7Ln_yl"
      },
      "source": [
        "Use progran-128 to generate a new target image from the latent space and display it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OTUoWdODbfr"
      },
      "source": [
        "Create a loss algorithm with MSE reduction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6k0KsCiDbmr"
      },
      "source": [
        "reduction = tf.keras.losses.Reduction.SUM\n",
        "loss_algorithm = tf.losses.MeanSquaredError(reduction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHE_fBNF3kfx"
      },
      "source": [
        "Clear previous model sessions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqNLe5bj3knQ"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzW19_lKDbr7"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypE4bKrrDbyJ"
      },
      "source": [
        "num_optimization_steps = 300\n",
        "steps_per_image = 5\n",
        "mse_images, mse_loss = find_closest_latent_vector(\n",
        "    feature_vector, uploaded_target, num_optimization_steps,\n",
        "    steps_per_image, loss_algorithm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEUxkpPDo9Bn"
      },
      "source": [
        "We trained the model on more optimization steps to generate a better facimile of the target image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLXG8vVfpIrI"
      },
      "source": [
        "Animate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-XzxyzRpIxp"
      },
      "source": [
        "animate(np.stack(mse_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O7CEP5EpMrO"
      },
      "source": [
        "Compare final generated image to the target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol-DFqpMpM0L"
      },
      "source": [
        "display_image(np.concatenate(\n",
        "    [mse_images[-1], uploaded_target], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X88ux1mnpM-X"
      },
      "source": [
        "Not bad. We can increase the number of optimization steps to generate a more realistic image. But be careful because setting the number of steps too high might compromise available RAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02gCIGsB5G-7"
      },
      "source": [
        "## Create a Target from a Google Drive Image\n",
        "\n",
        "Instead of grabbing an image from a local drive, grab it from Google Drive. We create a new feature vector, but you can just use the one created for the uploaded image exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2bhnvuA6u1N"
      },
      "source": [
        "Create an initial feature vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDa7NrHT6u7_"
      },
      "source": [
        "seed_value = 0\n",
        "tf.random.set_seed(seed_value)\n",
        "feature_vector = tf.random.normal([1, latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBI8kx-kARwd"
      },
      "source": [
        "Mount Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFwveq7uAR3Y"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b93iPEO2Axb7"
      },
      "source": [
        "Click on the URL, choose a Gmail account, copy the authorization code, paste it into the text box, and click the **Enter** button on your keypad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sanzmYO1BVYt"
      },
      "source": [
        "Get the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwxeH_IwBVfq"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "p1 = 'gdrive/My Drive/Colab Notebooks/'\n",
        "p2 = 'images/honest_abe.jpeg'\n",
        "path = p1 + p2\n",
        "img_path = path\n",
        "gdrive_image = Image.open(img_path)\n",
        "plt.axis('off')\n",
        "_ = plt.imshow(gdrive_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MLJVKLjBY6D"
      },
      "source": [
        "Create a path to the image on Google Drive. Open the image with the path and display. Be sure that the image is in the **Colab Notebooks** directory!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0olesISAqbD"
      },
      "source": [
        "Reformat the PIL image to the expected size of program-128:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnZnVYSZ8bMQ"
      },
      "source": [
        "def reformat(img, size):\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img) / 255.\n",
        "  img = tf.image.resize(img, size)\n",
        "  return img\n",
        "\n",
        "img_size = (128, 128)\n",
        "gdrive_vector = reformat(gdrive_image, img_size)\n",
        "gdrive_vector.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZVcBNmrA27D"
      },
      "source": [
        "The function converts the PIL image to a NumPy array and resizes it to the expected size of progran-128 (128 x 128 x 3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al_Lz6ekqWrT"
      },
      "source": [
        "Display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWqhOjEECTq3"
      },
      "source": [
        "display_image(gdrive_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htA4xUh6rrXs"
      },
      "source": [
        "The array is not the target image because it was not drawn from the latent space. Use progran-128 to generate the target image from a vector in the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybw73A5QrRhi"
      },
      "source": [
        "gdrive_target = hub_model(gdrive_vector)['default'][0]\n",
        "display_image(gdrive_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ceSfnhf6CwE"
      },
      "source": [
        "Create a loss algorithm with MSE reduction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRNKwMRU6C6E"
      },
      "source": [
        "reduction = tf.keras.losses.Reduction.SUM\n",
        "loss_algorithm = tf.losses.MeanSquaredError(reduction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndBwEp244jFo"
      },
      "source": [
        "Clear previous model sessions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrkqieMd4jNh"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0z1tPF6Klz"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrQV69j26Ks7"
      },
      "source": [
        "num_optimization_steps = 300\n",
        "steps_per_image = 5\n",
        "mse_images, mse_loss = find_closest_latent_vector(\n",
        "    feature_vector, gdrive_target, num_optimization_steps,\n",
        "    steps_per_image, loss_algorithm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dnKV_3g7SwX"
      },
      "source": [
        "Animate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhUMTFGp7S4l"
      },
      "source": [
        "animate(np.stack(mse_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BftcKVle8aYZ"
      },
      "source": [
        "Compare final generated image to target:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5gqsCjb8afA"
      },
      "source": [
        "display_image(np.concatenate(\n",
        "    [mse_images[-1], gdrive_target], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdM8nXxFYEm-"
      },
      "source": [
        "## Create a Target from Wikimedia Commons\n",
        "\n",
        "Grab an image from Wikimedia Commons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJAGGYNB2nZd"
      },
      "source": [
        "Generate a seed and create a feature vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxuWI-PRT_-g"
      },
      "source": [
        "seed_value = 0\n",
        "tf.random.set_seed(seed_value)\n",
        "feature_vector = tf.random.normal([1, latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqnv8esI2veX"
      },
      "source": [
        "Get the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQOBuWdVVrlV"
      },
      "source": [
        "p1 = 'http://upload.wikimedia.org/wikipedia/commons/'\n",
        "p2 = 'd/de/Wikipedia_Logo_1.0.png'\n",
        "URL = p1 + p2\n",
        "im = imageio.imread(URL)\n",
        "im.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pKAoEZ620tH"
      },
      "source": [
        "Convert the image to a NumPy array and display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UHz5h9FhDiY"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "img_array = img_to_array(im)\n",
        "print(img_array.dtype)\n",
        "print(img_array.shape)\n",
        "plt.imshow(tf.squeeze(img_array))\n",
        "fig = plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGlgP-tn2_gS"
      },
      "source": [
        "Resize image for progran-128 consumption:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1BLr65aZX9E"
      },
      "source": [
        "wiki_vector = tf.image.resize(img_array, (128, 128))\n",
        "plt.imshow(tf.squeeze(wiki_vector))\n",
        "fig = plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQebv82B3FDs"
      },
      "source": [
        "Create the target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_JV4WdjXNkQ"
      },
      "source": [
        "wiki_target = hub_model(wiki_vector)['default'][0]\n",
        "display_image(wiki_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhR2rET_3SjY"
      },
      "source": [
        "Create a loss algorithm with MSE reduction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ayVVK3H3Spe"
      },
      "source": [
        "reduction = tf.keras.losses.Reduction.SUM\n",
        "loss_algorithm = tf.losses.MeanSquaredError(reduction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVKVK1UL3Swn"
      },
      "source": [
        "Clear previous model session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "024nj_I43S2Y"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnE6T2yZ3S95"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZPI3WpZ3TDw"
      },
      "source": [
        "num_optimization_steps = 300\n",
        "steps_per_image = 5\n",
        "mse_images, mse_loss = find_closest_latent_vector(\n",
        "    feature_vector, wiki_target, num_optimization_steps,\n",
        "    steps_per_image, loss_algorithm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PnBrUJm5c1v"
      },
      "source": [
        "Animate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlOt_RgD5dCw"
      },
      "source": [
        "animate(np.stack(mse_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-2KSvwm5f2c"
      },
      "source": [
        "Compare:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS9kzd4aXNm3"
      },
      "source": [
        "display_image(np.concatenate(\n",
        "    [mse_images[-1], wiki_target], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vspdnh91vj_L"
      },
      "source": [
        "# Latent Vectors and Image Arrays\n",
        "\n",
        "The progran-128 module generates a new image from either a latent vector of size (1, 512) or float vector of size 128 x 128. A latent vector accepted by progran-128 is a 1-dimensional vector of size 512. A float vector accepted by progran-128 is 128 x 128 pixel vector.\n",
        "\n",
        "The proran-128 module is an image generator based on the TensorFlow re-implementation of Progressive GANs. It maps from a 512-dimensional latent space to images. During training, latent space vectors are sampled from a normal distribution.\n",
        "\n",
        "According to the documentation, progran-128 takes an input tensor with datatype float32 tensor and shape (?, 512). The input tensor to progran-128 represents a batch of latent vectors. The output from progran-128 is a float tensor with shape (?, 128, 128, 3), which represents a batch of RGB images. We can also generate a new image from an image array, which is not included in the documentation.\n",
        "\n",
        "To view progran-128 documentation, peruse:\n",
        "\n",
        "https://tfhub.dev/google/progan-128/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8Oi4F0_g3BG"
      },
      "source": [
        "## Generate a New Image from a Latent Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl6f0end1JOj"
      },
      "source": [
        "Create a random normal vector from the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RSHjl5Lvbah"
      },
      "source": [
        "random_normal_latent_vector = tf.random.normal([1, latent_dim])\n",
        "random_normal_latent_vector.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ryagADfGKOK"
      },
      "source": [
        "The tf.random.normal API outputs random values from a normal distribution. So the new vector consists of 512 randomly drawn values from a normal distribution of the latent space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cPRgZ6fAw4f"
      },
      "source": [
        "Convert the tensor to NumPy to enable inspection:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f2Q1gx6Aw_4"
      },
      "source": [
        "rnlv = random_normal_latent_vector.numpy()\n",
        "len(rnlv[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWwUZpB_BWNo"
      },
      "source": [
        "Inspect some elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ7LBKNQBWaX"
      },
      "source": [
        "for i, element in enumerate(rnlv[0]):\n",
        "  if i < 5:\n",
        "    print (element)\n",
        "  else: break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWDmgNuXB9xn"
      },
      "source": [
        "Each element in the new vector represents a latent dimension (or latent variable) that cannot be directory observed, but can be assumed to exist. Since latent dimensions exist, they can be used to explain patterns of variation in observed variables. In our experiment, observed variables represent CelebA images. So we can feed program-128 the new vector to generate a new image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGD-FFzY1d7M"
      },
      "source": [
        "Create a float output tensor from the latent space with progran-128:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hs797F5iBsG"
      },
      "source": [
        "float_output_tensor = hub_model(\n",
        "    random_normal_latent_vector)['default'][0]\n",
        "float_output_tensor.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Q8GcpNiduL"
      },
      "source": [
        "Display the float output tensor as an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmmeBixRvkGZ"
      },
      "source": [
        "display_image(generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWsgsEc1mBs"
      },
      "source": [
        "So progran-128 generates a 128 x 128 x 3 image from a latent vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxavCOv7hJjj"
      },
      "source": [
        "## Generate a New Image from an Image Vector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkwVqxp6hW0b"
      },
      "source": [
        "Get an image from Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l8A0EU3hnD-"
      },
      "source": [
        "p1 = 'gdrive/My Drive/Colab Notebooks/'\n",
        "p2 = 'images/honest_abe.jpeg'\n",
        "path = p1 + p2\n",
        "img_path = path\n",
        "abe_image = Image.open(img_path)\n",
        "plt.axis('off')\n",
        "_ = plt.imshow(abe_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW7bqbBsjHHt"
      },
      "source": [
        "Convert the JPEG image to an image vector of the appropriate datatype and size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk5TBNJejHTJ"
      },
      "source": [
        "img_size = (128, 128)\n",
        "abe_vector = reformat(abe_image, img_size)\n",
        "abe_vector.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv8V7ydrmJJE"
      },
      "source": [
        "Display a slice from the vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N1twA2ImJR4"
      },
      "source": [
        "abe_vector[0][0].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3YEorWewHI6"
      },
      "source": [
        "Generate a new image from the abe vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij-_8XQOwHSB"
      },
      "source": [
        "image_from_abe_vector = hub_model(abe_vector)['default'][0]\n",
        "display_image(image_from_abe_vector)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}