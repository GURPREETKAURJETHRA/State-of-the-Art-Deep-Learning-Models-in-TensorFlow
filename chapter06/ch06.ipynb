{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EXoS-8gwxlx"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "Image classification models have millions of parameters. Training them from scratch requires a lot of labeled training data and a lot of computing power. Transfer learning is a technique that shortcuts much of this by taking a piece of a model that has already been trained on a related task and reusing it in a new model.\n",
        "\n",
        "**Transfer learning** is the process of applying existing machine learning models to scenarios for which they were not originally intended. This leveraging can save training time and extend the usefulness of existing machine learning models, models which may have had the available data and computation to have been trained for very long periods of time on very large datasets. If we train a model on a large set of data, we can then refine the result to be effective on our smaller amount of data. At least, that's the idea.\n",
        "\n",
        "Documentation:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuZlMjQkO4TZ"
      },
      "source": [
        "# Import **tensorflow** Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bHZBZc4K-en"
      },
      "source": [
        "Import the library and alias it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8zzCdqgO4a4"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7UC2JNPw3pY"
      },
      "source": [
        "# GPU Hardware Accelerator\n",
        "\n",
        "To vastly speed up processing, we can use the GPU available from the Google Colab cloud service. Colab provides a free Tesla K80 GPU of about 12 GB. Itâ€™s very easy to enable the GPU in a Colab notebook:\n",
        "\n",
        "1.\tclick **Runtime** in the top left menu\n",
        "2.\tclick **Change runtime** type from the drop-down menu\n",
        "3.\tchoose **GPU** from the Hardware accelerator drop-down menu\n",
        "4.\tclick **SAVE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDNFpWCTw7L4"
      },
      "source": [
        "Verify that GPU is active:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck2w8yEvwqpp"
      },
      "source": [
        "tf.__version__, tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENnnXfKFC00"
      },
      "source": [
        "# Pre-trained Models for Transfer Learning\n",
        "\n",
        "If we don't have enough training data, it is often a good idea to reuse the lower layers of a pre-trained model. **Transfer learning** is the process of creating new AI models by fine-tuning previously trained neural networks. Instead of training a neural network from scratch, we can download a pretrained, open-source deep learning model and fine tune it for our own purpose.\n",
        "\n",
        "To implement transfer learning, we reuse parts of a pre-trained model and change the final layer (or several layers) of the model. We then retrain those layers on our own dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH4t09XuwbKq"
      },
      "source": [
        "# Simple Transfer Learning with TensorFlow Hub\n",
        "\n",
        "We model Flowers data by using pre-trained TF2 SavedModels from TensorFlow Hub for image feature extraction. The pre-trained models were trained on very large and general datasets.\n",
        "\n",
        "We use two pre-trained TensorFlow Hub models to do transfer learning. **TensorFlow Hub** is a repository of trained machine learning models ready for fine-tuning and deployable anywhere. We begin with the MobileNet v2 pre-trained model. We then use the Inception v3 pre-trained model and compare results between the two.\n",
        "\n",
        "Resources:\n",
        "\n",
        "https://www.tensorflow.org/hub\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0w1bpGuu0Ph"
      },
      "source": [
        "# MobileNet v2 Example\n",
        "\n",
        "Information about MobileNet and other pre-trained models is avaliable at the following URL:\n",
        "\n",
        "https://tfhub.dev/s?module-type=image-feature-vector&q=tf2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3T4YNQgG-N3"
      },
      "source": [
        "## Load flowers as TFDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxJ2XxwiClgK"
      },
      "source": [
        "Split 75% for train set, 15% for validation set, and 25% for test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wTU7RONG-TO"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(test, valid, train), info = tfds.load(\n",
        "    'tf_flowers', as_supervised=True,\n",
        "    split = ['train[:10%]', 'train[10%:25%]', 'train[25%:]'],\n",
        "    with_info=True, try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmkPOJ-iG-YG"
      },
      "source": [
        "## Get Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx3xxQjEJu9q"
      },
      "source": [
        "Display general information:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTXAcajOG-dG"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN_s6TK3G-he"
      },
      "source": [
        "Display number examples in data splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrQAa6GeG-me"
      },
      "source": [
        "num_train_img = info.splits['train[25%:]'].num_examples\n",
        "num_valid_img = info.splits['train[10%:25%]'].num_examples\n",
        "num_test_img = info.splits['train[:10%]'].num_examples\n",
        "print ('train images:', num_train_img)\n",
        "print ('valid images:', num_valid_img)\n",
        "print ('test images:', num_test_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG5NLjhYKpIR"
      },
      "source": [
        "Calculate number of examples in data splits manually to verify:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbkjuJV0Kb4Z"
      },
      "source": [
        "num_train_examples = 0\n",
        "num_valid_examples = 0\n",
        "num_test_examples = 0\n",
        "\n",
        "for example in train:\n",
        "  num_train_examples += 1\n",
        "\n",
        "for example in valid:\n",
        "  num_valid_examples += 1\n",
        "\n",
        "for example in test:\n",
        "  num_test_examples += 1\n",
        "\n",
        "print('Total Number of Training Images: {}'\\\n",
        "      .format(num_train_examples))\n",
        "print('Total Number of Validation Images: {}'\\\n",
        "      .format(num_valid_examples))\n",
        "print('Total Number of Testing Images: {}'\\\n",
        "      .format(num_test_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M--BAF0kKDxK"
      },
      "source": [
        "Get labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSRmdmIsKD2w"
      },
      "source": [
        "class_labels = info.features['label'].names\n",
        "class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRK9PcsAKHex"
      },
      "source": [
        "Get number of classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM16A6cJKHlI"
      },
      "source": [
        "num_classes = info.features['label'].num_classes\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWMmNDhzKM-5"
      },
      "source": [
        "## Display Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etyNc4QmC1xp"
      },
      "source": [
        "Display some examples with **show_examples**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGHKa5kDKTxp"
      },
      "source": [
        "fig = tfds.show_examples(train, info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8oX9dWmLvpr"
      },
      "source": [
        "## Inspect Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ATaMfY4C6Xv"
      },
      "source": [
        "Display shapes to check images sizes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv2oZaZdLvwz"
      },
      "source": [
        "for i, example in enumerate(train.take(5)):\n",
        "  print('Image {} shape: {} label: {}'\\\n",
        "        .format(i+1, example[0].shape,\n",
        "                example[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lnJJm-oL5jZ"
      },
      "source": [
        "The images in the flowers dataset are not all the same size. So, we must resize images to a standard size to make them consumable by TensorFlow models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BMod5pRK73p"
      },
      "source": [
        "## Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae0WhPz8DGiB"
      },
      "source": [
        "Create a function to reformat all images to the resolution expected by MobileNet v2 (224, 224) and scale them. The function takes an 'image' and a 'label' as arguments and returns the new 'image' and corresponding 'label' in the desired form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3qo8MNmK780"
      },
      "source": [
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (224, 224)) /255.0\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIy79Wq8DUiC"
      },
      "source": [
        "Map function to train, validation, and test sets. And, apply other transformations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq9zRe17M_ti"
      },
      "source": [
        "BATCH_SIZE = 367\n",
        "\n",
        "train_batches = train.shuffle(num_train_img//4).\\\n",
        "  map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "validation_batches = valid.map(format_image).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "test_batches = test.map(format_image).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9ND2p2wx5ka"
      },
      "source": [
        "## Simple Transfer Learning with MobileNet-v2\n",
        "\n",
        "We begin the process by creating  a feature_extractor. The partial model from TensorFlow Hub (without the final classification layer) is called a feature vector. Go to the TensorFlow Hub documentation (https://tfhub.dev/s?module-type=image-feature-vector) to see a list of available feature vectors.\n",
        "\n",
        "To get information about MobileNet-v2:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l06c03_exercise_flowers_with_transfer_learning_solution.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl4OEnjKO6oa"
      },
      "source": [
        "### Create a Feature Extractor\n",
        "\n",
        "Create a feature_extractor using the MobileNet-v2 feature vector. A **feature extractor** is the partial model from TensorFlow Hub (without the final classification layer).\n",
        "\n",
        "To see a list of available feature vectors, visit:\n",
        "\n",
        "https://tfhub.dev/s?module-type=image-feature-vector&q=tf2\n",
        "\n",
        "Click on one of them, read the documentation, and get the corresponding URL to get the feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bjuBKpnDaIr"
      },
      "source": [
        "Create the feature extractor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGN5Jr6QPck9"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "piece1 = 'https://tfhub.dev/google/tf2-preview/'\n",
        "piece2 = 'mobilenet_v2/feature_vector/4'\n",
        "URL = piece1 + piece2\n",
        "feature_extractor_mn = hub.KerasLayer(\n",
        "    URL, input_shape=(224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjRWGdFxSC7x"
      },
      "source": [
        "The feature extractor is now a partial MobileNet-v2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw43lTVWPnRV"
      },
      "source": [
        "## Freeze the Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9kQahuoDghk"
      },
      "source": [
        "Freeze the variables in the feature extractor layer, so that the training only modifies the final classifier layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgl_TlRSPnij"
      },
      "source": [
        "feature_extractor_mn.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWKd1iyBQCFd"
      },
      "source": [
        "## Attach a Classification Head\n",
        "\n",
        "Create a classification head to leverage the pre-trained model for the dataset, which consists of a simple sequential model that includes the pre-trained model and the new classification layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwBhqoCoRAVr"
      },
      "source": [
        "Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnv6li8bQ22C"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3mJoKNPW1Vb"
      },
      "source": [
        "Clear previous models and generate seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXRRHQvGW1cE"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZMxr4WMRCIb"
      },
      "source": [
        "Build model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yypC6MPPQCMm"
      },
      "source": [
        "mobile_model = tf.keras.Sequential([\n",
        "  feature_extractor_mn,\n",
        "  Dropout(0.5),\n",
        "  Dense(num_classes)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayOfuAe5REZb"
      },
      "source": [
        "Inspect model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkP7ZsQ8REgT"
      },
      "source": [
        "mobile_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhI6ImegRL0c"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62CAXyOmFLAA"
      },
      "source": [
        "Compile **SparseCategoricalCrossentropy**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RRZ19elRL6N"
      },
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "mobile_model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HgFrUxHRL-l"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56J55Lc8FSxN"
      },
      "source": [
        "Train model on train and validation sets for six epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQtBFEMBRMEF"
      },
      "source": [
        "EPOCHS = 6\n",
        "\n",
        "history = mobile_model.fit(\n",
        "    train_batches, epochs=EPOCHS,\n",
        "    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BJ5n6EuRj6d"
      },
      "source": [
        "We get good accuracy with just 6 epochs because MobileNet-v2 was carefully designed over a long time by experts and then trained on a massive dataset (ImageNet)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbH_oIP6TFlf"
      },
      "source": [
        "## Visualize Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV2CInmjFY7t"
      },
      "source": [
        "Plot model performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f2zopmrS6nR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X88gpnaTPxY"
      },
      "source": [
        "## Make Predictions from Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biEzYQS9Ff9b"
      },
      "source": [
        "Predict on **test_batches**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S49mKRpTP3x"
      },
      "source": [
        "predictions = mobile_model.predict(test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNctj1GNZsKc"
      },
      "source": [
        "Test data is pure because we haven't seen it yet!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asEZU59ufx--"
      },
      "source": [
        "Display class labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM7d4ZX2fyEa"
      },
      "source": [
        "class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7CkY_hHZYp1"
      },
      "source": [
        "### Inspect the First Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnEOyfn5eIVp"
      },
      "source": [
        "Get the first prediction array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OzOaQmYSTrN"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtVIdMx2Z6RV"
      },
      "source": [
        "The returned array is the raw prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WZprbu5eMmR"
      },
      "source": [
        "Use the np.argmax() function to get the prediction for the first image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JnnrBIwZ6XY"
      },
      "source": [
        "predicted_id = np.argmax(predictions[0])\n",
        "predicted_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEeMW4HqaPXl"
      },
      "source": [
        "Convert the label to its class name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3N1p1FcaPeQ"
      },
      "source": [
        "class_labels[predicted_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycTecXuZGeIn"
      },
      "source": [
        "Get the actual labels from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oSGEiX_GeOr"
      },
      "source": [
        "for img, lbl in test_batches.take(1):\n",
        "  print (lbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaKahEURG3UR"
      },
      "source": [
        "Get the first label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBxf8d_tG3gl"
      },
      "source": [
        "class_labels[lbl[0].numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBXIZ0vxHJEv"
      },
      "source": [
        "The prediction is correct if the actual label matches the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CcLQztMeEbj"
      },
      "source": [
        "### Inspect the First Batch of Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIV2BJbyaesu"
      },
      "source": [
        "Alternatively, we can convert *test_batches* to an iterator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNbfATXTbP1h"
      },
      "source": [
        "image_batch, label_batch = next(iter(test_batches))\n",
        "\n",
        "images = image_batch.numpy()\n",
        "labels = label_batch.numpy()\n",
        "\n",
        "class_labels[labels[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyyopo3fHqHg"
      },
      "source": [
        "Get the first batch from test_batches iterator with **next**, convert images and labels to NumPy, and display the first label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KynoSZMocbdk"
      },
      "source": [
        "Display labels from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWRueYicymH"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcwlb1bFe30Y"
      },
      "source": [
        "Convert the batch of labels to named labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdiK6Q4ye4I2"
      },
      "source": [
        "named_labels = [class_labels[labels[i]]\n",
        "                for i, lbl in enumerate(range(BATCH_SIZE))]\n",
        "named_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8OC80vgebDp"
      },
      "source": [
        "Get predictions from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryhNm6SQc0tY"
      },
      "source": [
        "predicted_batch = [np.argmax(predictions[i])\n",
        "                   for i, _ in enumerate(range(BATCH_SIZE))]\n",
        "predicted_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dhN7z4KgKSf"
      },
      "source": [
        "Convert predictions to named predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DjJihdqe3Eb"
      },
      "source": [
        "named_pred = [class_labels[predicted_batch[i]]\n",
        "              for i, lbl in enumerate(range(BATCH_SIZE))]\n",
        "named_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCpGxM23ejaM"
      },
      "source": [
        "## Plot Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a56GxOAzII9x"
      },
      "source": [
        "The visualization shows actual images from the first test batch. If the prediction is correct, the title is blue. If not, the title is red. If the prediction is incorrect, the prediction is displayed along with the actual label in parentheses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzeSIJm8ejoC"
      },
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.subplots_adjust(hspace = 0.3)\n",
        "  plt.imshow(images[n])\n",
        "  color = 'blue' if labels[n] == predicted_batch[n] else 'red'\n",
        "  if labels[n] != predicted_batch[n]:\n",
        "    t = named_pred[n].title() +\\\n",
        "        ' (' +named_labels[n].title() + ')'\n",
        "  else:\n",
        "    t = named_pred[n].title()\n",
        "  plt.title(t, color=color)\n",
        "  plt.axis('off')\n",
        "  st = 'Model predictions (blue: correct, red: incorrect)'\n",
        "_ = plt.suptitle(st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNJtM2ISiUrm"
      },
      "source": [
        "# Perform Transfer Learning with the Inception Model\n",
        "\n",
        "Use the Inception model to compare against MobileNet. To get the model, peruse https://tfhub.dev/s?module-type=image-feature-vector&q=tf2 and click on 'tf2-preview/inception_v3/feature_vector'. This feature vector corresponds to the Inception v3 model. Use transfer learning to create a CNN that uses Inception v3 as the pretrained model to classify the images from the Flowers dataset. Note that Inception takes as input images that are 299 x 299 pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76u7UnAhlh0B"
      },
      "source": [
        "## Reformat Images and Create Batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koMZP7TeISAq"
      },
      "source": [
        "Recreate the **format_image** function to reformat images to the resolution expected by Inception v3 (299, 299), and scale them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuoyOMQWlh8o"
      },
      "source": [
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (299, 299)) / 255.0\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7H7nCITliCg"
      },
      "source": [
        "## Build an Input Pipeline for Inception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywb5gqNqIpTI"
      },
      "source": [
        "Shuffle train data, reformat, batch, and prefetch train, validation, and test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGukQ5oQliNY"
      },
      "source": [
        "BATCH_SIZE = 367\n",
        "\n",
        "train_im = train.shuffle(num_train_img//4).\\\n",
        "  map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "validation_im = valid.map(format_image).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "test_im = test.map(format_image).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc8HwUN5kUBd"
      },
      "source": [
        "## Create a Feature Extractor\n",
        "\n",
        "Create a feature_extractor using the Inception v3 feature vector. A **feature extractor** is the partial model from TensorFlow Hub (without the final classification layer).\n",
        "\n",
        "To see a list of available feature vectors, visit:\n",
        "\n",
        "https://tfhub.dev/s?module-type=image-feature-vector&q=tf2\n",
        "\n",
        "Click on one of them, read the documentation, and get the corresponding URL to get the feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EUn646JBpS"
      },
      "source": [
        "Create the feature extractor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCJG_7A_iUyc"
      },
      "source": [
        "piece1 = 'https://tfhub.dev/google/tf2-preview/'\n",
        "piece2 = 'inception_v3/feature_vector/4'\n",
        "URL = piece1 + piece2\n",
        "feature_extractor_im = hub.KerasLayer(URL,\n",
        "  input_shape=(299, 299, 3),\n",
        "  trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo3LJq0uS4ak"
      },
      "source": [
        "Freeze the pre-trained layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2-3l7FrS3pF"
      },
      "source": [
        "feature_extractor_im.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydFK3WF7m84s"
      },
      "source": [
        "Clear and seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHDuFtVZm89k"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkLg09WoiU1e"
      },
      "source": [
        "## Create the Inception Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGyFrbA-JLU4"
      },
      "source": [
        "\n",
        "\n",
        "We've already set the stage with MobileNet. So we just need to subtitute the Inception feature extractor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xazyJWpxiU65"
      },
      "source": [
        "inception_model = tf.keras.Sequential([\n",
        "  feature_extractor_im,\n",
        "  Dropout(0.5),\n",
        "  Dense(num_classes)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OHJnI2RiU-l"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5rcwGMnJfAp"
      },
      "source": [
        "Compile with **SparseCategoricalCrossentropy(from_logits=True)**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jX0nOYXiVDk"
      },
      "source": [
        "inception_model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7pgOL3NnK9N"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VQQgDTZJkch"
      },
      "source": [
        "Train model for six epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ka4k-dknLB3"
      },
      "source": [
        "EPOCHS = 6\n",
        "\n",
        "history = inception_model.fit(\n",
        "    train_im, epochs=EPOCHS,\n",
        "    validation_data=validation_im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjCgXfVOAijJ"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4EAyBkEJ87N"
      },
      "source": [
        "Visualize model performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4Sz_dNAipc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A9NyBJyUpVQ"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj0AgshqUuZJ"
      },
      "source": [
        "Make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FnYdw27UpcD"
      },
      "source": [
        "im_predictions = inception_model.predict(test_im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1STd2R6UpyY"
      },
      "source": [
        "Get a batch of predictions and convert them to named predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8KcxLR-Up3R"
      },
      "source": [
        "im_pred_batch = [np.argmax(im_predictions[i])\n",
        "                 for i, _ in enumerate(range(BATCH_SIZE))]\n",
        "im_named_pred = [class_labels[im_pred_batch[i]]\n",
        "                 for i, lbl in enumerate(range(BATCH_SIZE))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWi7gCeJWfEZ"
      },
      "source": [
        "Grab the first batch of images and labels from the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqjjvhjgWfLY"
      },
      "source": [
        "im_image_batch, im_label_batch = next(iter(test_im))\n",
        "\n",
        "im_images = im_image_batch.numpy()\n",
        "im_labels = im_label_batch.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbwYqS-3VxDn"
      },
      "source": [
        "Convert the labels to named labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1u5CoMdVxLL"
      },
      "source": [
        "im_named_labels = [class_labels[im_labels[i]]\n",
        "                   for i, lbl in enumerate(range(BATCH_SIZE))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb6xTPeFVaDB"
      },
      "source": [
        "## Plot Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcEjndkhVNzS"
      },
      "source": [
        "Create a function to display predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQYpQAUYccJX"
      },
      "source": [
        "def plot_pred(images, labels, named_labels, named_pred):\n",
        "  plt.figure(figsize=(20,20))\n",
        "  for n in range(30):\n",
        "    plt.subplot(6,5,n+1)\n",
        "    plt.subplots_adjust(hspace = 0.3)\n",
        "    plt.imshow(images[n])\n",
        "    color = 'blue' if named_labels[n] == named_pred[n] else 'red'\n",
        "    if named_labels[n] != named_pred[n]:\n",
        "      t = named_pred[n].title() +\\\n",
        "      ' (' +named_labels[n].title() + ')'\n",
        "    else:\n",
        "      t = named_pred[n].title()\n",
        "    plt.title(t, color=color)\n",
        "    plt.axis('off')\n",
        "    st = 'Model predictions (blue: correct, red: incorrect)'\n",
        "    _ = plt.suptitle(st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZekwPu8bbo19"
      },
      "source": [
        "Invoke the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKUroLfbXOm"
      },
      "source": [
        "plot_pred(im_images, im_labels, im_named_labels, im_named_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}