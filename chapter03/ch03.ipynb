{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch03.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q5oHPRLAigSK",
        "_OTAqDdvk2FW"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5jHPF0vigFb"
      },
      "source": [
        "# TensorFlow Datasets\n",
        "\n",
        "TensorFlow Datasets (TFDS) provide a collection of ready-to-use datasets for use with TensorFlow, Jax, and other Machine Learning frameworks. It handles downloading and preparing the data deterministically and constructing a tf.data.Dataset (or np.array).\n",
        "\n",
        "Don't confuse TFDS (this library) with tf.data (TensorFlow API to build efficient data pipelines). TFDS is a high level wrapper around tf.data.\n",
        "\n",
        "The following resources contains basic information on TFDS:\n",
        "\n",
        "https://www.tensorflow.org/datasets/overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj3KPnMKigNR"
      },
      "source": [
        "# Import **tensorflow** Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9AyCIFNTRg"
      },
      "source": [
        "Import tensorflow library and alias as **tf**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNIBq9njKLl2"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5oHPRLAigSK"
      },
      "source": [
        "# GPU Hardware Accelerator\n",
        "\n",
        "To vastly speed up processing, we can use the GPU available from the Google Colab cloud service. Colab provides a free Tesla K80 GPU of about 12 GB. Itâ€™s very easy to enable the GPU in a Colab notebook:\n",
        "\n",
        "1.\tclick **Runtime** in the top left menu\n",
        "2.\tclick **Change runtime** type from the drop-down menu\n",
        "3.\tchoose **GPU** from the Hardware accelerator drop-down menu\n",
        "4.\tclick **SAVE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKlORNdpsbQx"
      },
      "source": [
        "# Test if GPU is Active"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_AjLo2LsbW9"
      },
      "source": [
        "tf.__version__, tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMgEU5LIsi8O"
      },
      "source": [
        "If '/device:GPU:0' is displayed, the GPU is active. If '..' is displayed, the regular CPU is active."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzsSeti4jf76"
      },
      "source": [
        "# Find Available Datasets\n",
        "\n",
        "All dataset builders are subclass of tfds.core.DatasetBuilder. To get the list of available builders, use tfds.list_builders()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyHh-6Y9j5-7"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.list_builders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XxF_iP8kEmC"
      },
      "source": [
        "Get number of datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qRuVqMWkE1y"
      },
      "source": [
        "len(tfds.list_builders())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqjvr4yDlIoy"
      },
      "source": [
        "To get a breakdown of the datasets, consult the following URL:\n",
        "\n",
        "https://www.tensorflow.org/datasets/catalog/overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIBqu7ErlLWC"
      },
      "source": [
        "# Load a Dataset\n",
        "\n",
        "All builders include a **tfds.core.DatasetInfo** object containing the dataset metadata, which is accessed through:\n",
        "\n",
        "* the tfds.load API\n",
        "* The tfds.core.DatasetBuilder API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDqbjZ_hlO2C"
      },
      "source": [
        "Load MNIST as a TFDS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFHWcU_UlLa7"
      },
      "source": [
        "ds, info = tfds.load('mnist', split='train',\n",
        "                     shuffle_files=True,\n",
        "                     with_info=True,\n",
        "                     try_gcs=True)\n",
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqtSbfzxlgqC"
      },
      "source": [
        "tfds.load downloads the data and saves it as **TFRecord** files. It then loads the TFRecord files and creates a tf.data.Dataset. The TFRecord format is a simple format for storing a sequence of binary records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7p_7twpmmHx"
      },
      "source": [
        "Some common arguments:\n",
        "\n",
        "* split - splits data (e.g. 'train', ['train', 'test'], 'train[80%:]',...)\n",
        "* shuffle_files - controls whether to shuffle the files between each epoch (TFDS store big datasets in multiple smaller files)\n",
        "* as_supervised - if True, tf.data.Dataset has a 2-tuple structure (input, label). If False, tf.data.Dataset has a dictionary structure\n",
        "* data_dir - location where the dataset is saved ( defaults to ~/tensorflow_datasets/)\n",
        "* with_info=True - returns the tfds.core.DatasetInfo containing dataset metadata\n",
        "* download=False - disables download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iSW_pjln7Qd"
      },
      "source": [
        "**tfds.load** is a thin wrapper around tfds.core.DatasetBuilder. You can get the same output using the tfds.core.DatasetBuilder API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3BF4WX1adQ2"
      },
      "source": [
        "The **MNIST** database is a large database of handwritten digits that is widely used for training and testing in the field of machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhkNVHOK8EN_"
      },
      "source": [
        "# Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI29jwUQ8ETE"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBPiTYkfa_vO"
      },
      "source": [
        "MNIST contains 60,000 28 x 28 feature images for training and 10,000 28 x 28 feature images for testing. Both train and test sets have corresponding labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6YRu_wyorVe"
      },
      "source": [
        "# Iterate Over a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzXjUzeCo1wc"
      },
      "source": [
        "## As dict\n",
        "\n",
        "By default, the tf.data.Dataset object contains a dict of tf.Tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHGAFQkQpFv9"
      },
      "source": [
        "Take a single training example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPaZUIfZo7ks"
      },
      "source": [
        "ds = ds.take(1)\n",
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbYMBgE_pOAF"
      },
      "source": [
        "Example is in the form:\n",
        "\n",
        " **{'image': tf.Tensor, 'label': tf.Tensor}**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr_m5C_1pfU8"
      },
      "source": [
        "Display:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Z8AC3ipbVU"
      },
      "source": [
        "for example in ds:\n",
        "  print ('keys:', list(example.keys()))\n",
        "  image = example['image']\n",
        "  label = example['label']\n",
        "  print ('shapes:', image.shape, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPfrTXj1pDMd"
      },
      "source": [
        "## As tuple (as_supervised=True)\n",
        "\n",
        "By using as_supervised=True, we get a tuple (features, label) for supervised datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8QLDulwpKFd"
      },
      "source": [
        "ds = tfds.load('mnist', split='train', as_supervised=True,\n",
        "               try_gcs=True)\n",
        "ds = ds.take(1)\n",
        "\n",
        "for image, label in ds:\n",
        "  print (image.shape, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7R7oUr3s2XR"
      },
      "source": [
        "We display by tuple pair - image, label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSbL35wsqE4P"
      },
      "source": [
        "## As numpy (tfds.as_numpy)\n",
        "\n",
        "Uses tfds.as_numpy to convert:\n",
        "\n",
        "* tf.Tensor -> np.array\n",
        "* tf.data.Dataset -> Generator[np.array]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BfZhHWbXth"
      },
      "source": [
        "Load train data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVKk89QcqRmH"
      },
      "source": [
        "ds = tfds.load('mnist', split='train', as_supervised=True,\n",
        "               try_gcs=True)\n",
        "ds = ds.take(1)\n",
        "\n",
        "for image, label in tfds.as_numpy(ds):\n",
        "  print (type(image), type(label), label)\n",
        "  print (image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVsndIZzdKTk"
      },
      "source": [
        "We loaded train data directly as a TFDS. We then converted it to numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNmT_jhtqkZJ"
      },
      "source": [
        "If we wish to load the entire dataset as numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS6UA1apqRwJ"
      },
      "source": [
        "image_train, label_train = tfds.as_numpy(\n",
        "    tfds.load('mnist', split='train',\n",
        "              batch_size=-1, as_supervised=True,\n",
        "              try_gcs=True))\n",
        "\n",
        "type(image_train), image_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMfNTXg6qx7T"
      },
      "source": [
        "By using batch_size=-1, the full dataset is loaded in a single batch. The batch is then converted to NumPy arrays.\n",
        "\n",
        "Be careful that your dataset can fit in memory and that all examples have the same shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO67deCGcVGS"
      },
      "source": [
        "### Inspect\n",
        "\n",
        "Since the dataset consists of NumPy arrays, we can inspect it with normal Python operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG-e0P2nVZpO"
      },
      "source": [
        "Get number of examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGW7be6Nb_vZ"
      },
      "source": [
        "len(list(image_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZk-l4zEUyGk"
      },
      "source": [
        "Inspect the first example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHSUj3LuUyL-"
      },
      "source": [
        "image_train[0].shape, label_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51F_Ew5gV3dQ"
      },
      "source": [
        "Inspect a few examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k18MkcjxV3mD"
      },
      "source": [
        "for row in range(3):\n",
        "  print (image_train[row].shape, label_train[row])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVRw-SzvrH9z"
      },
      "source": [
        "# Visualization\n",
        "\n",
        "We can conveniently visualize images from a TFDS. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gufXe83EuQOc"
      },
      "source": [
        "## tfds.as_dataframe\n",
        "\n",
        "To visualize image data, tf.data.Dataset objects can be converted to a pandas.DataFrame object:\n",
        "\n",
        "* add the tfds.core.DatasetInfo object as the second argument of the tfds.as_dataframe objet to visualize images, audio, texts, videos, and so on.\n",
        "* use ds.take(n) to display the first n examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isGYBGnDqE9_"
      },
      "source": [
        "ds, info = tfds.load('mnist', split='train', with_info=True,\n",
        "                     try_gcs=True)\n",
        "\n",
        "tfds.as_dataframe(ds.take(4), info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hWirlhAav-l"
      },
      "source": [
        "## Take Examples\n",
        "\n",
        "We can take some examples and visualize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvsXNGc--Mwr"
      },
      "source": [
        "Take some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpqz_P-C-M5Y"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images = []\n",
        "for example in ds.take(4):\n",
        "  img = tf.squeeze(example['image'])\n",
        "  images.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lqXoz8fcN3D"
      },
      "source": [
        "Take 4 examples, squeeze out the '1' dimension from each tensor, and add the squeezed tensors to an array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynR5Xy3cHs1"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKhyVw10axGF"
      },
      "source": [
        "rows, cols = 2, 2\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(rows*cols):\n",
        "  plt.subplot(rows, cols, i + 1)\n",
        "  plt.imshow(images[i], cmap='bone')\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNxCmkpWtQEo"
      },
      "source": [
        "## tfds.show_examples\n",
        "\n",
        "Only image datasets are supported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIE7L_N-tQJh"
      },
      "source": [
        "fig = tfds.show_examples(ds, info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiaP2YWTW15N"
      },
      "source": [
        "# Load Fashion-MNIST\n",
        "\n",
        "Load Fashion-MNIST as a TFDS. **Fashion-MNIST** is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. The dataset is intended to serve as a direct drop-in replacement of the original MNIST dataset for benchmarking machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5HfDxlFcyH3"
      },
      "source": [
        "Load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ2DXax1tyW4"
      },
      "source": [
        "fashion, fashion_info = tfds.load(\n",
        "    'fashion_mnist',\n",
        "    split='train',\n",
        "    with_info=True,\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T80MrCJ1a_uW"
      },
      "source": [
        "It's always a good idea to shuffle as much as possible!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOy_zySr88Fc"
      },
      "source": [
        "## Take an Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPTG40xpc4mx"
      },
      "source": [
        "Take one example and display image shape and label value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8Shgsy88On"
      },
      "source": [
        "for image, label in fashion.take(1):\n",
        "  print (image.shape, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT_hGjy0tCjz"
      },
      "source": [
        "## Inspect Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGWRSHhZdA8n"
      },
      "source": [
        "Display basic information about the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kf9eu63tCru"
      },
      "source": [
        "fashion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1buNIAzTuNJi"
      },
      "source": [
        "## Display info Object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knFQ8GPodKYP"
      },
      "source": [
        "View the contents of the **info** object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dJTjPDtuNQs"
      },
      "source": [
        "fashion_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNEswA3ercTc"
      },
      "source": [
        "From the info object, we can see a lot of information about the dataset. A very important one is how the data is split. In this case, the data is already split into train and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jtqmxFYuXIE"
      },
      "source": [
        "## Show Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TCijcPQ4pA-"
      },
      "source": [
        "Display some example with the **show_examples** function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSMNjQ-ouXM0"
      },
      "source": [
        "fig = tfds.show_examples(fashion, fashion_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llc8aAuEdplA"
      },
      "source": [
        "Nine examples are displayed along with their class labels by integer and name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVHfWYoY4jRw"
      },
      "source": [
        "Display examples with **as_dataframe**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E88lRO8x4jYr"
      },
      "source": [
        "tfds.as_dataframe(fashion.take(4), info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YOC4SS9uDcm"
      },
      "source": [
        "The first example from the dataset contains a 28 x 28 x 1 image with a corresponding label of 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-yiPCDjpIA0"
      },
      "source": [
        "Take some examples and visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MYf77azpIJd"
      },
      "source": [
        "classes = fashion_info.features['label'].names\n",
        "images, labels = [], []\n",
        "for image, label in fashion.take(4):\n",
        "  img = tf.squeeze(image)\n",
        "  images.append(img), labels.append(label)\n",
        "\n",
        "rows, cols = 2, 2\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(rows*cols):\n",
        "  plt.subplot(rows, cols, i + 1)\n",
        "  plt.imshow(images[i], cmap='bone')\n",
        "  t = classes[labels[i]] + ' (' +\\\n",
        "      str(labels[i].numpy()) + ')'\n",
        "  plt.title(t)\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itZXXFZb_49C"
      },
      "source": [
        "## Display Metadata (label names, image shape,...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8M_Iv8NALin"
      },
      "source": [
        "Access the tfds.features.FeatureDict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzvbx0vu_5B4"
      },
      "source": [
        "fashion_info.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWaCXyv4AI4P"
      },
      "source": [
        "Number of classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEiKvTBFAI9_"
      },
      "source": [
        "num_classes = fashion_info.features['label'].num_classes\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Z8rI1HU-pm"
      },
      "source": [
        "Class names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a43cIvnaU-x5"
      },
      "source": [
        "classes = fashion_info.features['label'].names\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udqAp-jAAS84"
      },
      "source": [
        "Shapes, dtypes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVDJXFmJATC4"
      },
      "source": [
        "print (fashion_info.features.shape)\n",
        "print (fashion_info.features.dtype)\n",
        "print (fashion_info.features['image'].shape)\n",
        "print (fashion_info.features['image'].dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ithx2ctfBxp9"
      },
      "source": [
        "## Display Split Metadata (e.g. split names, available splits, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZz4HUbQB32x"
      },
      "source": [
        "Access the tfds.core.SplitDict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMjG_eyGBxvr"
      },
      "source": [
        "fashion_info.splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmSJTHS-B7lh"
      },
      "source": [
        "Available splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baXmFvIoB7rh"
      },
      "source": [
        "list(fashion_info.splits.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxtdjhvWCA8J"
      },
      "source": [
        "Get info on individual split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC9IEU6dCBCQ"
      },
      "source": [
        "print (fashion_info.splits['train'].num_examples)\n",
        "print (fashion_info.splits['train'].filenames)\n",
        "print (fashion_info.splits['train'].num_shards)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZaLOGc1CanC"
      },
      "source": [
        "# Splitting and Splicing API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruJoya1YDJOj"
      },
      "source": [
        "All DatasetBuilders expose various data subsets defined as splits (eg: train, test). When constructing a tf.data.Dataset instance using either tfds.load() or tfds.DatasetBuilder.as_dataset(), one can specify which split(s) to retrieve. It is also possible to retrieve slice(s) of split(s) as well as combinations of those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6cIv3yqDQ6j"
      },
      "source": [
        "## Slicing API\n",
        "\n",
        "Slicing instructions are specified in tfds.load or tfds.DatasetBuilder.as_dataset.\n",
        "\n",
        "Instructions can be provided as either strings or ReadInstructions. Strings are more compact and readable for simple cases, while ReadInstructions provide more options and might be easier to use with variable slicing parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crdmdYLfDOXT"
      },
      "source": [
        "Note: Due to the shards being read in parallel, order isn't guaranteed to be consistent between sub-splits. In other words reading test[0:100] followed by test[100:200] may yield examples in a different order than reading test[:200]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Fem23lDgyu"
      },
      "source": [
        "## Examples using the string API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5SGPwXiEIBO"
      },
      "source": [
        "Full 'train' split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4INnuzlMCask"
      },
      "source": [
        "fashion_train = tfds.load('fashion_mnist', split='train',\n",
        "                          try_gcs=True)\n",
        "fashion_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uClVYhgD0p2"
      },
      "source": [
        "Full 'train' split and the full 'test' split as two distinct datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs_N32PTD0ww"
      },
      "source": [
        "train_ds, test_ds = tfds.load('fashion_mnist',\n",
        "                              split=['train', 'test'],\n",
        "                              try_gcs=True)\n",
        "train_ds, test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83XF2VcED01L"
      },
      "source": [
        "Full 'train' and 'test' splits, **interleaved** together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HJtr2EBD06H"
      },
      "source": [
        "train_test_ds = tfds.load('fashion_mnist', split='train+test',\n",
        "                          try_gcs=True)\n",
        "train_test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSGLYx_TEroP"
      },
      "source": [
        "From record 100 (included) to record 200 (excluded) of 'train' split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVcVOdbLErtV"
      },
      "source": [
        "train_100_200_ds = tfds.load('fashion_mnist',\n",
        "                             split='train[100:200]',\n",
        "                             try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz_4SbacFEVa"
      },
      "source": [
        "First 25% of 'train' split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjizmDhIFEZ5"
      },
      "source": [
        "train_25pct_ds = tfds.load('fashion_mnist',\n",
        "                           split='train[:25%]',\n",
        "                           try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTmFh-LfFQhZ"
      },
      "source": [
        "First 10% of 'train' + the last 80% of 'train':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4_S4XQfFhOc"
      },
      "source": [
        "train_10_80pct_ds = tfds.load(\n",
        "    'fashion_mnist', try_gcs=True,\n",
        "    split='train[:10%]+train[-80%:]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTXvWsYKF9eI"
      },
      "source": [
        "10-fold cross-validation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KzEtI6oF9lM"
      },
      "source": [
        "test_cv = tfds.load('fashion_mnist', try_gcs=True,\n",
        "                    split=[f'train[{k}%:{k+10}%]'\n",
        "                    for k in range(0, 100, 10)])\n",
        "train_cv = tfds.load('fashion_mnist', try_gcs=True,\n",
        "                      split=[f'train[:{k}%]+train[{k+10}%:]'\n",
        "                      for k in range(0, 100, 10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV2KFTn5GXb0"
      },
      "source": [
        "10-fold cross-validation:\n",
        "* validation datasets are each going to be 10%:\n",
        "[0%:10%], [10%:20%], ..., [90%:100%].\n",
        "* training datasets are each going to be the complementary 90%:\n",
        "[10%:100%] (for a corresponding validation set of [0%:10%]),\n",
        "[0%:10%] + [20%:100%] (for a validation set of [10%:20%]), ...,\n",
        "[0%:90%] (for a validation set of [90%:100%])."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QeQZwjuGo6P"
      },
      "source": [
        "## Examples using the ReadInstruction API (equivalent as above):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D1dwNVocGdX"
      },
      "source": [
        "Full 'train' split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoZF_MTZcGjN"
      },
      "source": [
        "train_ds = tfds.load('fashion_mnist', try_gcs=True,\n",
        "                     split=tfds.core.ReadInstruction('train'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxFoKfEgcGru"
      },
      "source": [
        "Full 'train' split and full 'test' split as two distinct datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC-YiJL1cGxI"
      },
      "source": [
        "train_ds, test_ds = tfds.load(\n",
        "    'fashion_mnist', try_gcs=True,\n",
        "    split=[tfds.core.ReadInstruction('train'),\n",
        "           tfds.core.ReadInstruction('test')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EREKcx4IcG4u"
      },
      "source": [
        "Full 'train' and 'test' splits, interleaved together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcZ5g-E8cG-f"
      },
      "source": [
        "ri = tfds.core.ReadInstruction('train')\\\n",
        "     + tfds.core.ReadInstruction('test')\n",
        "train_test_ds = tfds.load('fashion_mnist',\n",
        "                          split=ri, try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypkuBMXqdJuH"
      },
      "source": [
        "From record 100 (included) to record 200 (excluded) of 'train' split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mDDHgMBdJ0F"
      },
      "source": [
        "train_100_200_ds = tfds.load(\n",
        "    'fashion_mnist',\n",
        "    split=tfds.core.ReadInstruction(\n",
        "        'train', from_=100, to=200,\n",
        "        unit='abs'), try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGGJQiymdZ2W"
      },
      "source": [
        "First 25% of 'train' split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLYt9iqVdZ8K"
      },
      "source": [
        "train_25_pct_ds = tfds.load(\n",
        "    'fashion_mnist', try_gcs=True,\n",
        "    split=tfds.core.ReadInstruction(\n",
        "        'train', to=25, unit='%'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smtyb9j3d3N4"
      },
      "source": [
        "First 10% of 'train' to last 80% of train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGmpxb9hd3Tg"
      },
      "source": [
        "ri = (tfds.core.ReadInstruction('train', to=10, unit='%') +\n",
        "      tfds.core.ReadInstruction('train', from_=-80, unit='%'))\n",
        "train_10_80pct_ds = tfds.load('fashion_mnist',\n",
        "                              split=ri, try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL6HujcLeCTQ"
      },
      "source": [
        "10-fold cross-validation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXFgKrM4FQnu"
      },
      "source": [
        "tests = tfds.load('fashion_mnist', split=\n",
        "    [tfds.core.ReadInstruction('train', from_=k,\n",
        "                               to=k+10, unit='%')\n",
        "     for k in range(0, 100, 10)], try_gcs=True)\n",
        "trains = tfds.load('fashion_mnist', split=\n",
        "    [tfds.core.ReadInstruction('train', to=k, unit='%') +\n",
        "     tfds.core.ReadInstruction('train', from_=k+10, unit='%')\n",
        "     for k in range(0, 100, 10)], try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3TDCGaEeHgi"
      },
      "source": [
        "* validation datasets are each going to be 10%: [0%:10%], [10%:20%], ..., [90%:100%].\n",
        "* training datasets are each going to be the complementary 90%:\n",
        "[10%:100%] (for a corresponding validation set of [0%:10%]),\n",
        "[0%:10%] + [20%:100%] (for a validation set of [10%:20%]), ...,\n",
        "[0%:90%] (for a validation set of [90%:100%])."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfKYd_HGDqF"
      },
      "source": [
        "# Performance Tips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OTAqDdvk2FW"
      },
      "source": [
        "## Auto-caching\n",
        "\n",
        "By default, TFDS auto-caches datasets which satisfy the following constraints:\n",
        "* total dataset size (all splits) is defined and < 250 MB\n",
        "* shuffle_files is disabled or only a single shard is read\n",
        "\n",
        "It is possible to opt out of auto-caching by passing try_autocaching=False to tfds.ReadConfig in tfds.load. Have a look at the dataset catalog documentation to see if a specific dataset will use auto-cache.\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://www.tensorflow.org/datasets/performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DG4myKzj3tw"
      },
      "source": [
        "## Benchmark Datasets\n",
        "\n",
        "Use tfds.core.benchmark(ds) to benchmark any tf.data.Dataset object. Make sure to indicate the **batch_size =** to *some value*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c69N1-sweSw2"
      },
      "source": [
        "Load and preprocess a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r_Y9okl5Xjv"
      },
      "source": [
        "ds = tfds.load('fashion_mnist', split='train',\n",
        "               try_gcs=True).batch(32).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-79_6el5aFs"
      },
      "source": [
        "Benchmark:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAYSIu1B5bsX"
      },
      "source": [
        "tfds.core.benchmark(ds, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu9ozsq05fxV"
      },
      "source": [
        "Run a second iteration benchmark:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpvzve7P5isO"
      },
      "source": [
        "tfds.core.benchmark(ds, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNjJYG0u5n7O"
      },
      "source": [
        "The second iteration benchmark is much faster due to auto-caching!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwT7uyjtlVDe"
      },
      "source": [
        "# Load Fashion-MNIST as a Single Tensor\n",
        "\n",
        "If your dataset fits into memory, you can also load the full dataset as a single Tensor or NumPy array. It is possible to do so by setting batch_size=-1 to batch all examples in a single tf.Tensor. In this case, we load the full dataset as a numpy array with tfds.as_numpy to convert the tf.Tensor to np.array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgwfdsCj3QFO"
      },
      "source": [
        "Load the train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3XOn9lElVJn"
      },
      "source": [
        "(img_train, label_train), (img_test, label_test) = tfds.as_numpy(\n",
        "    tfds.load(\n",
        "        'fashion_mnist', try_gcs=True, as_supervised=True,\n",
        "        split=['train', 'test'], batch_size=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAhaXwLBliHe"
      },
      "source": [
        "Display shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5UYIwKLliMZ"
      },
      "source": [
        "img_train.shape, label_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9u-z4pMFrv0"
      },
      "source": [
        "Get input shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e23ef3kjFPxK"
      },
      "source": [
        "img_shape = img_train.shape[1:]\n",
        "img_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdzYd4PNFtkM"
      },
      "source": [
        "## Ready for TensorFlow Consumption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMef18A9fgvp"
      },
      "source": [
        "Prepare train and test sets for TensorFlow consumption:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbwEaAAgEZlI"
      },
      "source": [
        "train = img_train / 255.0\n",
        "test = img_test / 255.0\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (train, label_train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (test, label_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZLuH09AFyx7"
      },
      "source": [
        "## Build Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4bH07ZxfmUQ"
      },
      "source": [
        "Build input pipelines for train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m96_t5rkEZnw"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "SHUFFLE_SIZE = 5000\n",
        "\n",
        "train_f = train_ds.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE)\n",
        "train_fm = train_f.cache().prefetch(1)\n",
        "\n",
        "test_f = test_ds.batch(BATCH_SIZE)\n",
        "test_fm = test_f.cache().prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SVz7yXKF1eL"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sJ1qhK8f3Bx"
      },
      "source": [
        "Import requisite libraries for modeling data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LJ0l41-EZs2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA9q3JGWd1jo"
      },
      "source": [
        "## Clear Previous Models and Generate Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBHtn_K3gEFp"
      },
      "source": [
        "Clear previous models and generate seed with various tools:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHssD8ehd1pC"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWuSXBySF3G6"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5wIDYHTgMxX"
      },
      "source": [
        "Build the feedforward network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt5MLlCtEZqZ"
      },
      "source": [
        "model = Sequential([\n",
        "  Flatten(input_shape=img_shape),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dropout(0.4),\n",
        "  Dense(num_classes, activation=None)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tb-_T5hF5BS"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD3AUTJbgezx"
      },
      "source": [
        "Compile with **SparseCategoricalCrossentropy(from_logits=True)**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXzIlUagFX59"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA0UFrZ5F7fL"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ5gCa7NglbY"
      },
      "source": [
        "Train for ten epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BzUmXPCEZvI"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(train_fm, epochs=epochs,\n",
        "                    verbose=1, validation_data=test_fm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ZmEGnkXfG9"
      },
      "source": [
        "# Load Beans Dataset as TFDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf1ecgOxg0LJ"
      },
      "source": [
        "Load the beans dataset as a TFDS. Set **as_supervised** to True to return (img, label) instead of dict(image=, ...):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TKD3eoLXfPf"
      },
      "source": [
        "beans, beans_info = tfds.load(\n",
        "    'beans', with_info=True, as_supervised=True,\n",
        "    try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLcYDZHIyf4h"
      },
      "source": [
        "Inspect data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6c8hbHOyf_w"
      },
      "source": [
        "beans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUULvZM0eO-q"
      },
      "source": [
        "The dataset is already split into test, train and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzaT6kapXfUl"
      },
      "source": [
        "## Inspect info Object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgOD5j-Bg7Lh"
      },
      "source": [
        "Display **info** object contents:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm0u7RkHXfa3"
      },
      "source": [
        "beans_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxQtUE27Xfga"
      },
      "source": [
        "## Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrtFCygdY5WH"
      },
      "source": [
        "Shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5z05W55Ywu7"
      },
      "source": [
        "beans['train'], beans['test'], beans['validation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe5SkKaTYwza"
      },
      "source": [
        "Splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR-9cPHSYxAD"
      },
      "source": [
        "beans_info.splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdC3iFIYxEx"
      },
      "source": [
        "Labels and number of classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq9e_mxuYxKP"
      },
      "source": [
        "class_labels = beans_info.features['label'].names\n",
        "num_classes = beans_info.features['label'].num_classes\n",
        "class_labels, num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdzvg5nKYxO4"
      },
      "source": [
        "## Display Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCiSoNw3yBbH"
      },
      "source": [
        "Use **show_examples** to display some examples::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1ZvB-SlZOFd"
      },
      "source": [
        "fig = tfds.show_examples(beans['train'], beans_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY0fsWUAekHT"
      },
      "source": [
        "Labels are displayed as class name and numerical value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2f7VibJyESs"
      },
      "source": [
        "Use **as_dataframe** to display examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opKNcRR9x2l1"
      },
      "source": [
        "tfds.as_dataframe(beans['train'].take(4), info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0bvnD63zyBF"
      },
      "source": [
        "Letâ€™s build a grid to display more examples. Begin by selecting images from the train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_xM0gZ8zyHk"
      },
      "source": [
        "num = 30\n",
        "images, labels = [], []\n",
        "for feature, label in beans['train'].take(num):\n",
        "  images.append(tf.squeeze(feature.numpy()))\n",
        "  labels.append(label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmss2uiUz-AL"
      },
      "source": [
        "Create a function to display a grid of examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xupf_MUez-G4"
      },
      "source": [
        "def display_grid(feature, target, n_rows, n_cols, cl):\n",
        "  plt.figure(figsize=(n_cols * 1.5, n_rows * 1.5))\n",
        "  for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "      index = n_cols * row + col\n",
        "      plt.subplot(n_rows, n_cols, index + 1)\n",
        "      plt.imshow(feature[index], cmap='twilight',\n",
        "                 interpolation='nearest')\n",
        "      plt.axis('off')\n",
        "      t = ' ('  + str(target[index]) + ')'\n",
        "      plt.title(cl[target[index]] + t, fontsize=7.5)\n",
        "  plt.subplots_adjust(wspace=0.2, hspace=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Q2CJbl0H6c"
      },
      "source": [
        "Plot the grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaPSKsfr0IA-"
      },
      "source": [
        "rows, cols = 5, 6\n",
        "display_grid(images, labels, rows, cols, class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14EZ9RJWyITd"
      },
      "source": [
        "Display the first healthy bean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWxbZJeJYxUN"
      },
      "source": [
        "for img, lbl in beans['train'].take(30):\n",
        "  if lbl.numpy() == 2:\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    print (class_labels[lbl.numpy()], end=' ')\n",
        "    print (lbl.numpy())\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MB3yx7gZxKU"
      },
      "source": [
        "## Check Shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSKLf159hkB6"
      },
      "source": [
        "Check five examples to examine image shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRlDsiuPZxQb"
      },
      "source": [
        "for i, example in enumerate(beans['train'].take(5)):\n",
        "  print('Image {} shape: {} label: {}'.\\\n",
        "        format(i+1, example[0].shape, example[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvbCjuGRa3-m"
      },
      "source": [
        "## Reformat\n",
        "\n",
        "Resize to a smaller size for performance and scale:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPBm6UMkZtaG"
      },
      "source": [
        "IMAGE_RES = 224\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdTCOTtwhsG5"
      },
      "source": [
        "Although shapes are of the same size, resize to a smaller size to improve modeling performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxvjmYTbZmWw"
      },
      "source": [
        "## Configure Dataset for Performance\n",
        "\n",
        "Use buffered prefetching and caching to improve I/O performance.\n",
        "\n",
        "Prefetching overlaps the preprocessing and model execution of a training step. While the model is executing training step **s**, the input pipeline is reading the data for step **s+1**. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data. The tf.Dataset.prefetch transformation overlaps data preprocessing and model execution while training.\n",
        "\n",
        "The tf.data.Dataset.cache transformation can cache a dataset, either in memory or on local storage. This save some operations (like file opening and data reading) from being executed during each epoch. Specifically, Dataset.cache keeps the images in memory after they're loaded off disk during the first epoch. This ensures that the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://www.tensorflow.org/guide/data_performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKQY1DUPh2o6"
      },
      "source": [
        "Build the input pipeline for train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw1O-gU9Zmb6"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_SIZE = 500\n",
        "\n",
        "train_batches = beans['train'].shuffle(SHUFFLE_SIZE).\\\n",
        "  map(format_image).batch(BATCH_SIZE).cache().prefetch(1)\n",
        "\n",
        "validation_batches = beans['test'].\\\n",
        "  map(format_image).batch(BATCH_SIZE).cache().prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olUOkE2YZmgo"
      },
      "source": [
        "## Get Input Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh5wpo5yh8zy"
      },
      "source": [
        "Place input shape into a variable for use in the network model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSY5-2Pxbxvw"
      },
      "source": [
        "for img, lbl in train_batches.take(1):\n",
        "  in_shape = img.shape[1:]\n",
        "in_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhbvBGf8ZmqL"
      },
      "source": [
        "## Import New Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eda4l7eSiDN1"
      },
      "source": [
        "Import libraries not already in memory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1To1ZJhrZmxD"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwfM1Cg_1g-h"
      },
      "source": [
        "## Clear Previous Models and Generate Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3LY3dN9iHOc"
      },
      "source": [
        "Clear previous models and generate seed with various tools:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C6Tvorbbd-E"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNsE4RTt1jx5"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWJj_Q9eiWl8"
      },
      "source": [
        "Create a multilayered CNN model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjBCSJChbd7-"
      },
      "source": [
        "model = Sequential([\n",
        "  Conv2D(32, (3, 3), activation = 'relu',\n",
        "         input_shape=in_shape, strides=1,\n",
        "         kernel_regularizer='l1_l2'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(64, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Flatten(),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dense(num_classes, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZnn8Bp11lv7"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLJ81Zykijtg"
      },
      "source": [
        "Compile with **tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PAXkYJFbd5s"
      },
      "source": [
        "loss = tf.keras.losses.\\\n",
        "       SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT8Gmg4t1nWq"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aPD3x6-irlY"
      },
      "source": [
        "Train for ten epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DFbhi2hZml9"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_batches, epochs=epochs,\n",
        "    verbose=1, validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHC4q6Te-fgU"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM3aZsC7_cp-"
      },
      "source": [
        "Make predictions based on the validation dataset because it has never been seen by the model. Build an input pipeline for the validation set to ready it for predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge0mbr7x-flC"
      },
      "source": [
        "validate = beans['validation'].\\\n",
        "  map(format_image).batch(BATCH_SIZE).cache().prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIgd0kqn_4mu"
      },
      "source": [
        "Make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--09WFvl_4ra"
      },
      "source": [
        "predictions = model.predict(validate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f47rXQ9P-4Qs"
      },
      "source": [
        "Get the prediction for the first example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnX0l9_Z-4W4"
      },
      "source": [
        "first_prediction = tf.math.argmax(predictions[0])\n",
        "class_labels[first_prediction.numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84ZCEhFoAEbH"
      },
      "source": [
        "Get multiple predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt22zLi0AEh4"
      },
      "source": [
        "p = []\n",
        "for row in range(8):\n",
        "  pred = tf.math.argmax(predictions[row])\n",
        "  p.append(pred.numpy())\n",
        "  print ('class:', '(' + str(pred.numpy()) + ')', end=' ')\n",
        "  print (class_labels[pred.numpy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogEIGauqCWcy"
      },
      "source": [
        "Get an idea of model accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDTLKLeOCWju"
      },
      "source": [
        "for i, (_, label) in enumerate(beans['validation'].take(8)):\n",
        "  if label.numpy() == p[i]:\n",
        "    print ('correct')\n",
        "  else:\n",
        "    print ('incorrect', end=' ')\n",
        "    print ('actual:', label.numpy(), 'predicted:', p[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}