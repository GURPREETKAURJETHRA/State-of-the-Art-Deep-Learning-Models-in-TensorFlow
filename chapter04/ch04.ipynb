{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ch04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4rSUBqz4i5X"
      },
      "source": [
        "# Deep Learning with TensorFlow Datasets\n",
        "\n",
        "We work through an end-to-end deep learning experiment with a large and complex TFDS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXssPiFVLB-G"
      },
      "source": [
        "# Import **tensorflow** Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y1iWNTCi8oA"
      },
      "source": [
        "Import library and alias it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d2LvGF3LCcl"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PnMQkbb7gNF"
      },
      "source": [
        "# GPU Hardware Accelerator\n",
        "\n",
        "To vastly speed up processing, we can use the GPU available from the Google Colab cloud service. Colab provides a free Tesla K80 GPU of about 12 GB. Itâ€™s very easy to enable the GPU in a Colab notebook:\n",
        "\n",
        "1.\tclick **Runtime** in the top left menu\n",
        "2.\tclick **Change runtime** type from the drop-down menu\n",
        "3.\tchoose **GPU** from the Hardware accelerator drop-down menu\n",
        "4.\tclick **SAVE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sch88ir7j7K"
      },
      "source": [
        "# Test if GPU is Active"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PPut3PujNKq"
      },
      "source": [
        "Verify that the GPU is active in this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDY0lNPa_Xp2"
      },
      "source": [
        "tf.__version__, tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRrO40D57pLc"
      },
      "source": [
        "Import the **tensorflow** library. If '/device:GPU:0' is displayed, the GPU is active. If '..' is displayed, the regular CPU is active."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dIc6pWz71J8"
      },
      "source": [
        "# Train **cats_vs_dogs** TFDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdV6KSyMjRsZ"
      },
      "source": [
        "Load **cats_vs_dogs** dataset with simple parameters to get its metadata:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_coapFR_UzA"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "data, info = tfds.load(name='cats_vs_dogs', with_info=True,\n",
        "                       try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNAOtz3Ifeer"
      },
      "source": [
        "The dataset contains a large set of images of cats and dogs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__4kw-iM8COE"
      },
      "source": [
        "## Access Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mpgGG0GjdPZ"
      },
      "source": [
        "Display contents of the **info** object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOAnRMk5_yj4"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1uUGCjEVSWz"
      },
      "source": [
        "Get labels and number of classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMFs5oE1VSdD"
      },
      "source": [
        "class_labels = info.features['label'].names\n",
        "num_classes = info.features['label'].num_classes\n",
        "class_labels, num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_shJ_D4HVfb1"
      },
      "source": [
        "Get number of train, validation, and test examples for a 80/10/10 split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zwZqQ1SVfly"
      },
      "source": [
        "num_train_img = info.splits['train[0%:80%]'].num_examples\n",
        "num_validation_img = info.splits['train[80%:90%]'].num_examples\n",
        "num_test_img = info.splits['train[90%:100%]'].num_examples\n",
        "print ('train images:', num_train_img)\n",
        "print ('validation images:', num_validation_img)\n",
        "print ('test images:', num_test_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv1Hd_LyVt0U"
      },
      "source": [
        "Validate number of examples in each split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9PHNEdUVt6g"
      },
      "source": [
        "train_num = num_train_img /23262\n",
        "validation_num = num_validation_img /23262\n",
        "test_num = num_test_img /23262\n",
        "\n",
        "'{0:.0%}'.format(train_num), '{0:.0%}'.format(validation_num),\\\n",
        "'{0:.0%}'.format(test_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoFv7kT69A34"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaPd3Tsijk9B"
      },
      "source": [
        "Now that we know the splits for the dataset, we can split the dataset or load it with the splits that we want. Let's just load the dataset with an 80/10/10 split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b27ZaT809H5p"
      },
      "source": [
        "(training_set, validation_set, test_set), info = tfds.load(\n",
        "    'cats_vs_dogs', with_info=True,\n",
        "    split=['train[:80%]', 'train[80%:90%]',\n",
        "           'train[90%:]'], shuffle_files=True,\n",
        "    as_supervised=True, try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhceuca0tIRx"
      },
      "source": [
        "The split is 80% train and 10% each for validation and test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LInn7JYaWD1W"
      },
      "source": [
        "Just to be sure, manually check splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIwCgXomWD6s"
      },
      "source": [
        "len(list(training_set)), len(list(validation_set)),\\\n",
        "len(list(test_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iISto3oZ9dYj"
      },
      "source": [
        "## Display Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1nDXYgujtow"
      },
      "source": [
        "Display some examples with **show_examples**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr7U4Q6s9IBm"
      },
      "source": [
        "fig = tfds.show_examples(training_set, info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhSNyM3-lgbg"
      },
      "source": [
        "Display as a dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx0jOCZWlgh2"
      },
      "source": [
        "tfds.as_dataframe(training_set.take(4), info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDFTdCFNl95J"
      },
      "source": [
        "Display manually. Begin by taking some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSNV2Sopl9_Y"
      },
      "source": [
        "images, labels = [], []\n",
        "for img, lbl in training_set.take(4):\n",
        "  img = tf.squeeze(img)\n",
        "  images.append(img), labels.append(lbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo1-2DY0mPOR"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcSzs5ydmPWw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rows, cols = 2, 2\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(rows*cols):\n",
        "  plt.subplot(rows, cols, i + 1)\n",
        "  plt.imshow(images[i], cmap='bone')\n",
        "  t = class_labels[labels[i]] + ' (' +\\\n",
        "      str(labels[i].numpy()) + ')'\n",
        "  plt.title(t)\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qOGFvbkBUsl"
      },
      "source": [
        "## Display Element Specification for Train Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srrDE-1mkKbg"
      },
      "source": [
        "Display train set information with **element_spec**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxsgi7reBUzr"
      },
      "source": [
        "training_set.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKsYwRfOAKpq"
      },
      "source": [
        "## Inspect Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrnHgiTQrqQm"
      },
      "source": [
        "Take some examples and convert them to numpy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_GhezzFruLl"
      },
      "source": [
        "features, labels = [], []\n",
        "for img, lbl in training_set.take(4):\n",
        "  img = tfds.as_numpy(img)\n",
        "  lbl = tfds.as_numpy(lbl)\n",
        "  features.append(img)\n",
        "  labels.append(lbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKBHrPMkrxtc"
      },
      "source": [
        "Create empty lists. Take four examples, convert TFDS images and labels to numpy with **tfds.as_numpy**, and append to lists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM7m8Yz-sAfm"
      },
      "source": [
        "Display examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e0-FD8tsA4d"
      },
      "source": [
        "rows, cols = 2, 2\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(rows*cols):\n",
        "  c = class_labels[labels[i]]\n",
        "  s = str(features[i].shape)\n",
        "  title = c + ' ' + s\n",
        "  plt.subplot(rows, cols, i + 1)\n",
        "  plt.title(title)\n",
        "  plt.imshow(features[i], cmap='binary')\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg2hvKyEC7kG"
      },
      "source": [
        "Images have different shapes. So we must resize them to the same shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MsUTRaLBU32"
      },
      "source": [
        "## Reformat Images\n",
        "\n",
        "We can resize images to any size, but it is faster to train a model with smaller images. So resize images to 150 Ã— 150 pixels. The function resizes and scales images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WHzqQ0pBVEE"
      },
      "source": [
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (150, 150))/255.0\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NANP63GyMsgX"
      },
      "source": [
        "## Configure Dataset for Performance\n",
        "\n",
        "Use buffered prefetching and caching to improve I/O performance.\n",
        "\n",
        "Prefetching overlaps the preprocessing and model execution of a training step. While the model is executing training step **s**, the input pipeline is reading the data for step **s+1**. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data. The tf.Dataset.prefetch transformation overlaps data preprocessing and model execution while training.\n",
        "\n",
        "The tf.data.Dataset.cache transformation can cache a dataset, either in memory or on local storage. This save some operations (like file opening and data reading) from being executed during each epoch. Specifically, Dataset.cache keeps the images in memory after they're loaded off disk during the first epoch. This ensures that the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://www.tensorflow.org/guide/data_performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrcR_ApQBVIU"
      },
      "source": [
        "## Prepare Data for TensorFlow Consumption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnrDRlg7ubF2"
      },
      "source": [
        "Shuffle train data. Resize and scale train, validation, and test data by mapping **format_image** onto the datasets. Batch, cache, and prefetch the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZD0bWBBVN-"
      },
      "source": [
        "BATCH_SIZE = 200\n",
        "SHUFFLE_SIZE = 500\n",
        "\n",
        "train_batches = training_set.shuffle(SHUFFLE_SIZE).\\\n",
        "map(format_image).batch(BATCH_SIZE).cache().prefetch(1)\n",
        "\n",
        "validation_batches = validation_set.\\\n",
        "map(format_image).batch(BATCH_SIZE).cache().prefetch(1)\n",
        "\n",
        "test_batches = test_set.\\\n",
        "map(format_image).batch(BATCH_SIZE).cache().prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNy0AVBDEfEp"
      },
      "source": [
        "Display element specification for training batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t64aD_07EfJx"
      },
      "source": [
        "train_batches.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCmFz38kW7D4"
      },
      "source": [
        "Inspect all tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8gc7t9CW6Oh"
      },
      "source": [
        "train_batches, validation_batches, test_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9gt9gxCXG-V"
      },
      "source": [
        "## Visualize Images from a Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skDa_hOnXMHC"
      },
      "source": [
        "Grab the first batch from the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZHLT8h2XMOJ"
      },
      "source": [
        "for img, lbl in train_batches.take(1):\n",
        "  print (img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMA85PKgXMT2"
      },
      "source": [
        "Inspect the first image from the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBiJ7y5DXMY6"
      },
      "source": [
        "img[0].shape, class_labels[lbl[0].numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr_EYRQyXWaM"
      },
      "source": [
        "Grab some images from the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geJo7n6JXHFF"
      },
      "source": [
        "images, labels = [], []\n",
        "for i in range(4):\n",
        "  tf.squeeze(img[i])\n",
        "  images.append(img[i]), labels.append(lbl[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUawaohWXgEF"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h_vfFfwXgKu"
      },
      "source": [
        "rows, cols = 2, 2\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(rows*cols):\n",
        "  plt.subplot(rows, cols, i + 1)\n",
        "  plt.imshow(images[i], cmap='bone')\n",
        "  t = class_labels[labels[i]] + ' (' +\\\n",
        "      str(labels[i].numpy()) + ')'\n",
        "  plt.title(t)\n",
        "  plt.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTYMUqYaf5CW"
      },
      "source": [
        "## Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KWI-p58usuW"
      },
      "source": [
        "Place input shape into a variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQmeJtef5Im"
      },
      "source": [
        "for img, lbl in train_batches.take(1):\n",
        "  in_shape = img.shape[1:]\n",
        "in_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzAsaCYbE2Sl"
      },
      "source": [
        "Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGQ85NHxQCBO"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,\\\n",
        "Dense, Flatten, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AGKdH3CE6nc"
      },
      "source": [
        "Clear previous models and generate seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv4oIPHVQCDZ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsBvNZpHFFBI"
      },
      "source": [
        "Build the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AbwaOfvQJjf"
      },
      "source": [
        "model = Sequential([\n",
        "  Conv2D(32, (3, 3), activation = 'relu',\n",
        "         input_shape=in_shape, strides=1,\n",
        "         kernel_regularizer='l1_l2'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(64, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Flatten(),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dense(num_classes, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLgP4jaFvzgJ"
      },
      "source": [
        "Inspect the model with **summary()**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-YHtabFI-lf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9rVQkInJDq3"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvLZwNqqv4gp"
      },
      "source": [
        "Compile with **tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3VkjhSIQLKX"
      },
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvSDjm8FJF1V"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_740FQP4v98Z"
      },
      "source": [
        "Train for ten epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgyHE8ugQOV_"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(train_batches, epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYvQteZLYW-u"
      },
      "source": [
        "## Generalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VV-ScerYXFb"
      },
      "source": [
        "loss, acc = model.evaluate(test_batches)\n",
        "print ('loss:', loss)\n",
        "print ('accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui3c56pWMocJ"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ6c15LRwBoq"
      },
      "source": [
        "Create a function to visualize model performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umv1WPWVHjSZ"
      },
      "source": [
        "def viz(hd):\n",
        "  acc = hd['accuracy']\n",
        "  val_acc = hd['val_accuracy']\n",
        "  loss = hd['loss']\n",
        "  val_loss = hd['val_loss']\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(acc, label='Training Accuracy')\n",
        "  plt.plot(val_acc, label='Validation Accuracy')  \n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(loss, label='Training Loss')\n",
        "  plt.plot(val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ6D3OFr0QX3"
      },
      "source": [
        "Invoke:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EiDVHNG0Qe-"
      },
      "source": [
        "viz(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgEiPbWBM7oi"
      },
      "source": [
        "# Data Augmentation with Keras Preprocessing Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9C0oF2HwUxD"
      },
      "source": [
        "To mitigate overfitting and hopefully improve model performance, we use data augmentation. Begin by implementing data augmentation using experimental Keras Preprocessing Layers. Let's try random horizontal flips, random rotation, and random zoom:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOdb9VoTW45O"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpY2SH1-PjpX"
      },
      "source": [
        "## Display an Augmented Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvNvhRBHwYy7"
      },
      "source": [
        "Here is what happens when applying data augmentation to the same image several times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G03GL7lHOP9m"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_batches.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X1SEWY0SVAb"
      },
      "source": [
        "## Clear Previous Models and Generate Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl2zxJlLwwhN"
      },
      "source": [
        "Clear previous models and generate seed with various tools:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACk4EaDpSVHY"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bulVqN0HSa_J"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJZlFA4Nw8Th"
      },
      "source": [
        "Create a multilayered CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_fT3fkOPK0O"
      },
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  Conv2D(32, (3, 3), activation = 'relu',\n",
        "         input_shape=in_shape, strides=1,\n",
        "         kernel_regularizer='l1_l2'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(64, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Flatten(),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dense(num_classes, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxl_mGEkSitp"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4HvMiFexCTM"
      },
      "source": [
        "Compile with **tf.keras.losses.SparseCategoricalCrossentropy(              from_logits=True)**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqYCWY_4PK2d"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                  from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXlmYFuSldI"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwcF7JgnxKuT"
      },
      "source": [
        "Train model for ten epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrxnW7-tPK6M"
      },
      "source": [
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "epochs = 10\n",
        "history = model.fit(train_batches, epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkXfqvZUY0fj"
      },
      "source": [
        "## Generalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXuyYP2IY0mE"
      },
      "source": [
        "loss, acc = model.evaluate(test_batches)\n",
        "print ('loss:', loss)\n",
        "print ('accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwnkDAXkVi7M"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s47ZgLxHxOzz"
      },
      "source": [
        "Visualize model performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgeVMUUx0ev-"
      },
      "source": [
        "viz(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IePYjNjrqitN"
      },
      "source": [
        "Validation accuracy has a better trajectory with data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZJuJgvsJt2q"
      },
      "source": [
        "# Implement Data Augmentation on Images\n",
        "\n",
        "Implement data augmentation by performing transformations on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DedFIoJUxhCd"
      },
      "source": [
        "Create functions to augment images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY1dn94ujlAv"
      },
      "source": [
        "def random_crop(image):\n",
        "    shape = tf.shape(image)\n",
        "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
        "    return tf.image.random_crop(image, [min_dim, min_dim, 3])\n",
        "\n",
        "def preprocess(image, label):\n",
        "  cropped_image = random_crop(image)\n",
        "  cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
        "  resized_image = tf.image.resize(cropped_image, [150, 150])\n",
        "  final_image = tf.keras.applications.xception.preprocess_input(\n",
        "      resized_image)\n",
        "  return final_image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qPPPtV7jjRw"
      },
      "source": [
        "The random_crop function randomly crops images. The preprocess function crops based on the randomized parameter and resizes image. The **tf.keras.applications.xception.preprocess_input** utility preprocesses a tensor or numpy array by encoding a batch of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2pDqFgF3SPz"
      },
      "source": [
        "## Display an Augmented Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAl3cm4h3uha"
      },
      "source": [
        "Show what happens to an image with augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adRH5trN3SXN"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_batches.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    Images = np.clip(augmented_images, 0, 1)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(Images[0])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My3T-FaANVwc"
      },
      "source": [
        "## Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en3OuSVmxzvB"
      },
      "source": [
        "Import the **partial** package, set batch and shuffle size, and build the pipeline: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKVsEMw4JuMc"
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "BATCH_SIZE = 200\n",
        "SHUFFLE_SIZE = 500\n",
        "\n",
        "train_shuffle = training_set.shuffle(1000)\n",
        "train_batches = train_shuffle.map(partial(preprocess)).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.map(preprocess).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_set.map(preprocess).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOaXq_K-pxxx"
      },
      "source": [
        "Partial functions fix a certain number of arguments of a function and generate a new function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_cj7g2OLelM"
      },
      "source": [
        "## Clear Previous Models and Generate Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHH2oIPTyClu"
      },
      "source": [
        "Clear previous models and seed with various tools:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcjlv6axLChx"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G8L6qG4NYK0"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VZYPKe9yHRq"
      },
      "source": [
        "Create a multilayered CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUlmqofZLCj2"
      },
      "source": [
        "model = Sequential([\n",
        "  Conv2D(32, (3, 3), activation = 'relu',\n",
        "         input_shape=in_shape, strides=1,\n",
        "         kernel_regularizer='l1_l2'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(64, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2),\n",
        "  Conv2D(128, (3, 3), activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Flatten(),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dense(num_classes, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij8pg7BxNaHk"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy8QbkE1yOEY"
      },
      "source": [
        "Compile with **tf.keras.losses.SparseCategoricalCrossentropy(                 from_logits=True)**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao_dKEERLCma"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                  from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct658VS6Nb-s"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPpjFSZqyUSL"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFRT6djTLIOz"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(train_batches, epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJl4KtW3ZPsq"
      },
      "source": [
        "## Generalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWb-sf4MZPzJ"
      },
      "source": [
        "loss, acc = model.evaluate(test_batches)\n",
        "print ('loss:', loss)\n",
        "print ('accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olVvhY7S1SKx"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdD1fKjvyYsZ"
      },
      "source": [
        "Visualize model performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLXXRxV21SWP"
      },
      "source": [
        "viz(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fK58kZd0jJ9"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s90uP2L0meE"
      },
      "source": [
        "We can make predictions on the whole dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj13e2_J0jQd"
      },
      "source": [
        "predictions = model.predict(test_batches)\n",
        "list(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgqQpK_g1Hbo"
      },
      "source": [
        "Predict on 'test_batches' because it has never been seen by the model. The *predict()* method returns NumPy arrays of predictions. For classification experiments, each element in a prediction array represents a class label. In our experiment, we have two classes (cats and dogs). So each prediction array has two elements. The value of each element is a probability. The magnitude of the probability represents the likelihood that the element is the predicted class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvh4Nk1m_QGo"
      },
      "source": [
        "Return the prediction for the first example: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQpMwoso_QV-"
      },
      "source": [
        "first_prediction = tf.math.argmax(predictions[0])\n",
        "class_labels[first_prediction.numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V0HhbbR0swg"
      },
      "source": [
        "We can also make predictions on a single batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAHIYrAe0s5s"
      },
      "source": [
        "first_batch = test_batches.take(1)\n",
        "predict_batch = model.predict(first_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR66eAzg7I8k"
      },
      "source": [
        "Get the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wNQWquV7JD8"
      },
      "source": [
        "first_batch_prediction = tf.math.argmax(predict_batch[0])\n",
        "class_labels[first_batch_prediction.numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOW2eakL3Zna"
      },
      "source": [
        "Get the first actual label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcZ00oB73ZuR"
      },
      "source": [
        "for image, label in first_batch:\n",
        "  print ('batch size:', image.shape[0])\n",
        "class_labels[label[0].numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76VfzFM3_3sI"
      },
      "source": [
        "If the first prediction matches the first actual label, the prediction is correct!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoecjjjK4yxB"
      },
      "source": [
        "Manually check the prediction accuracy of the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rroxQqW94y4A"
      },
      "source": [
        "cnt = 0\n",
        "for i in range(image.shape[0]):\n",
        "  pred = tf.math.argmax(predict_batch[i]).numpy()\n",
        "  actual = label[i].numpy()\n",
        "  if actual == pred:\n",
        "    cnt += 1\n",
        "acc = cnt / image.shape[0]\n",
        "'{percent:.2%}'.format(percent=acc) + ' accuracy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELjAMtZIEHk-"
      },
      "source": [
        "## Visualize Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgClyXaUds9B"
      },
      "source": [
        "Grab the first batch of images and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plzh_slOU-Mx"
      },
      "source": [
        "for img, lbl in test_batches.take(1):\n",
        "  print (img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq8sH49LdxnA"
      },
      "source": [
        "Each batch contains 200 150 x 150 color images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEe9krLnd2wQ"
      },
      "source": [
        "Inspect the first image from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7oESRatU-Pb"
      },
      "source": [
        "img[0].shape, class_labels[lbl[0].numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bjsSETPd7G4"
      },
      "source": [
        "Visualize the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8W0jlEuiqfK"
      },
      "source": [
        "Image= np.clip(img[0], 0, 1)\n",
        "fig = plt.imshow(Image)\n",
        "fig = plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAAbL9x4eCXf"
      },
      "source": [
        "Process some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lXBzNfdRqcg"
      },
      "source": [
        "images, labels = [], []\n",
        "for i in range(20):\n",
        "  tf.squeeze(img[i])\n",
        "  images.append(img[i]), labels.append(lbl[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01QP7gTWeGkg"
      },
      "source": [
        "We have 20 imaes and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKKvvtWPXYfO"
      },
      "source": [
        "len(images), len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUdbmLS_eULt"
      },
      "source": [
        "Create a function to display a set of images and labels. The function determines if a prediction is correct or incorrect. Correct predictions are displayed normally, but incorrect predictions are displayed in red text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyCvsbUFYihk"
      },
      "source": [
        "def display_test(feature, target, num_images,\n",
        "                 n_rows, n_cols, cl, p):\n",
        "  for i in range(num_images):\n",
        "    plt.subplot(n_rows, 2*n_cols, 2*i+1)\n",
        "    Image= np.clip(feature[i], 0, 1)\n",
        "    plt.imshow(Image)\n",
        "    pred = cl[tf.math.argmax(p[i]).numpy()]\n",
        "    actual = cl[target[i]]\n",
        "    title_obj = plt.title(actual + ' (' +\\\n",
        "                          pred + ') ')\n",
        "    if pred == actual:\n",
        "      title_obj\n",
        "    else:\n",
        "      plt.getp(title_obj, 'text')\n",
        "      plt.setp(title_obj, color='r')\n",
        "    plt.tight_layout()\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4GNWnoCeyBB"
      },
      "source": [
        "Invoke the function for the images we processed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqGjOmcOYij4"
      },
      "source": [
        "num_rows, num_cols = 5, 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(20, 20))\n",
        "display_test(images, labels, num_images, num_rows,\n",
        "             num_cols, class_labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO9iF1ObCkPJ"
      },
      "source": [
        "# Train **rock_paper_scissors** TFDS\n",
        "\n",
        "The dataset contains images of hands playing the rock-paper-scissors game.\n",
        "\n",
        "For an excellent tutorial on training the dataset, peruse:\n",
        "\n",
        "https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_cnn/rock_paper_scissors_cnn.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfH0vlR2fzg1"
      },
      "source": [
        "## Configure TensorBoard\n",
        "\n",
        "**TensorBoard** is a tool that provides measurements and visualizations during the machine learning workflow. It tracks experiment metrics including loss, accuracy, model graph visualization, and embedding projections to a lower dimensional space.\n",
        "\n",
        "For a nice tutorial, peruse:\n",
        "\n",
        "https://www.tensorflow.org/tensorboard/get_started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLz74K3sg0rN"
      },
      "source": [
        "Load the TensorBoard notebook extension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bkt9pdLfznT"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hkbt_znXjje"
      },
      "source": [
        "Import requisite library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th3hyzijXjpy"
      },
      "source": [
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tt3KN1bhCsD"
      },
      "source": [
        "Clear logs from previous runs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDrxGd6HhCy-"
      },
      "source": [
        "!rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VSmOyL0DwrT"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpPmOY0sCkR-"
      },
      "source": [
        "Load the train and test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbK3zgJ3UXzv"
      },
      "source": [
        "(train_digits, test_digits), rps_info = tfds.load(\n",
        "    'rock_paper_scissors', with_info=True,\n",
        "    data_dir='tmp', as_supervised=True,\n",
        "    split=['train', 'test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS4RvXdwEIeW"
      },
      "source": [
        "## Inspect Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQLCuINH69JQ"
      },
      "source": [
        "Get metadata:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpFLEIqk69TG"
      },
      "source": [
        "rps_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fkfJQyFCksw"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMOJoV8-CkyJ"
      },
      "source": [
        "fig = tfds.show_examples(train_digits, rps_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1_Yk5gdDzf7"
      },
      "source": [
        "Get number of examples and class labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUPDpFplDzlC"
      },
      "source": [
        "train_examples = rps_info.splits['train'].num_examples\n",
        "test_examples = rps_info.splits['test'].num_examples\n",
        "num_labels = rps_info.features['label'].num_classes\n",
        "train_examples, test_examples, num_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjCUUSyfEoIB"
      },
      "source": [
        "Get shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKN9pbNwEoM2"
      },
      "source": [
        "rps_info.features['image'].shape,\\\n",
        "rps_info.features['label'].shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmdDBRsLFhez"
      },
      "source": [
        "Get label names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufbIIKcQFhlj"
      },
      "source": [
        "label_name = rps_info.features['label'].int2str\n",
        "for lbl in range(num_labels):\n",
        "  print (label_name(lbl), end=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp7KifMyHlbR"
      },
      "source": [
        "Inspect image shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40GmfEkgHljQ"
      },
      "source": [
        "for image, label in train_digits.take(5):\n",
        "  print (image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENPE1FX1HVlg"
      },
      "source": [
        "## Preprocess the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd1tXNodXuB_"
      },
      "source": [
        "Reduce image size in half:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sroiM81sVhXp"
      },
      "source": [
        "new_pixels = rps_info.features['image'].shape[0] // 2\n",
        "new_pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRMnRtHlIC65"
      },
      "source": [
        "Create a preprocessing function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V23OT66GX3nC"
      },
      "source": [
        "def format_digits(image, label):\n",
        "  image = tf.cast(image, tf.float32) / 255.\n",
        "  image = tf.image.resize(image, [new_pixels, new_pixels])\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhxa57-BHdxG"
      },
      "source": [
        "Although images are of the same size, resize them to use less memory during training. Scale images to be in the \\[0, 1] range to improve training performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LWQddpsHVxe"
      },
      "source": [
        "Preprocess train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMKboLTcHV2q"
      },
      "source": [
        "train_original = train_digits.map(format_digits)\n",
        "test_original = test_digits.map(format_digits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osXpvxNpJlF1"
      },
      "source": [
        "Explore an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc9jmk9iGBO0"
      },
      "source": [
        "for image, label in train_original.take(1):\n",
        "  finger_img_shape = image.shape\n",
        "  print (image.shape, image[0][0].numpy(), label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va6QWGGYJxK2"
      },
      "source": [
        "## Visualize Processed Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JvNgEe5KWmI"
      },
      "source": [
        "Create a function to visualize data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4vjSP59JxQA"
      },
      "source": [
        "def preview_dataset(dataset):\n",
        "  plt.figure(figsize = (12, 12))\n",
        "  plot_index = 0\n",
        "  for image, label in dataset.take(12):\n",
        "    plot_index += 1\n",
        "    plt.subplot(3, 4, plot_index)\n",
        "    plt.axis('Off')\n",
        "    label = label_name(label.numpy())\n",
        "    plt.title(label)\n",
        "    plt.imshow(image.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-_6fD9J2gd"
      },
      "source": [
        "Invoke the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjCQ6Z_-J2oW"
      },
      "source": [
        "preview_dataset(train_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmXlYIncK8fC"
      },
      "source": [
        "## Augment Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1jlleheLpv6"
      },
      "source": [
        "### Create Data Augmentation Functions\n",
        "\n",
        "Images coming into the functions are transformed to TensorFlow tensors by the **tf.Tensor** API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbwVIpESLuZT"
      },
      "source": [
        "Create a function to randomly flip images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzc4Yw7NK8l8"
      },
      "source": [
        "def flip(image: tf.Tensor) -> tf.Tensor:\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  image = tf.image.random_flip_up_down(image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8A1JZckL_3O"
      },
      "source": [
        "Create a function to randomly augment color and clip the image to the \\[0, 1] range:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ung2oDLQL_-j"
      },
      "source": [
        "def color(image: tf.Tensor) -> tf.Tensor:\n",
        "  image = tf.image.random_hue(\n",
        "      image, max_delta=0.2)\n",
        "  image = tf.image.random_saturation(\n",
        "      image, lower=0.7, upper=1.3)\n",
        "  image = tf.image.random_brightness(image, 0.05)\n",
        "  image = tf.image.random_contrast(\n",
        "      image, lower=0.8, upper=1)\n",
        "  image = tf.clip_by_value(\n",
        "      image, clip_value_min=0, clip_value_max=1)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-bfyJsnMAEs"
      },
      "source": [
        "Create a function to randomly rotate an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9FWNkpfMAKI"
      },
      "source": [
        "def rotate(image: tf.Tensor) -> tf.Tensor:\n",
        "  return tf.image.rot90(\n",
        "      image,\n",
        "      tf.random.uniform(\n",
        "          shape=[], minval=0,\n",
        "          maxval=4, dtype=tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ_oSTeCMAPd"
      },
      "source": [
        "Create a function to randomly invert an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25U3XN-FMAVu"
      },
      "source": [
        "def invert(image: tf.Tensor) -> tf.Tensor:\n",
        "  random = tf.random.uniform(\n",
        "      shape=[], minval=0, maxval=1)\n",
        "  if random > 0.5:\n",
        "    image = tf.math.multiply(image, -1)\n",
        "    image = tf.math.add(image, 1)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn87YOKDMAaM"
      },
      "source": [
        "Create a function to zoom an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGH8TUtAQsGt"
      },
      "source": [
        "def zoom(\n",
        "    image: tf.Tensor, min_zoom=0.8, max_zoom=1.0) -> tf.Tensor:\n",
        "  image_width, image_height, image_colors = image.shape\n",
        "  crop_size = (image_width, image_height)\n",
        "  scales = list(np.arange(min_zoom, max_zoom, 0.01))\n",
        "  boxes = np.zeros((len(scales), 4))\n",
        "  for i, scale in enumerate(scales):\n",
        "    x1 = y1 = 0.5 - (0.5 * scale)\n",
        "    x2 = y2 = 0.5 + (0.5 * scale)\n",
        "    boxes[i] = [x1, y1, x2, y2]\n",
        "  def random_crop(img):\n",
        "    crops = tf.image.crop_and_resize(\n",
        "        [img], boxes=boxes,\n",
        "        box_indices=np.zeros(len(scales)),\n",
        "        crop_size=crop_size)\n",
        "    return crops[tf.random.uniform(shape=[],\n",
        "                 minval=0, maxval=len(scales),\n",
        "                 dtype=tf.int32)]\n",
        "  choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "  return tf.cond(choice < 0.5, lambda: image, lambda: random_crop(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Wo1qlrN44y"
      },
      "source": [
        "The function generates crop settings ranging from 1% to 20%. It then creates bounding boxes to hold the cropped images. The returned cropped images is resized to keep the size uniform for training. Cropping is only performed 50% of the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNFNHOCtPNaN"
      },
      "source": [
        "Create an augment function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJDv91PhPNgG"
      },
      "source": [
        "def augment_data(image, label):\n",
        "  image = flip(image)\n",
        "  image = color(image)\n",
        "  image = rotate(image)\n",
        "  image = zoom(image)\n",
        "  image = invert(image)\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b14azdiJQarf"
      },
      "source": [
        "## Augment Train Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6KJWymePZNm"
      },
      "source": [
        "Map the augmentations to the train data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG0CjA5-PZTm"
      },
      "source": [
        "train_augmented = train_original.map(augment_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REPjBgI5QlmD"
      },
      "source": [
        "Visualize the augmentated train data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BXeEYwtQJq7"
      },
      "source": [
        "preview_dataset(train_augmented)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VusU7FDGQsgH"
      },
      "source": [
        "Visualize the original test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMD9JZboQvZ4"
      },
      "source": [
        "preview_dataset(test_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Hn3v4_Q8G9"
      },
      "source": [
        "## Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XrsZMkIRAIw"
      },
      "source": [
        "Instantiate train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYhXvPvhRAOh"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_fingers = train_augmented.shuffle(train_examples).cache().\\\n",
        "  batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "test_fingers = test_original.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbqN-f9VRz1y"
      },
      "source": [
        "Prefetch enables the input pipeline to asynchronously fetch batches while the model is training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXvTwPejTuHz"
      },
      "source": [
        "## Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efPVACHUS-_"
      },
      "source": [
        "Clear and seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eumf3bt5TuOv"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZIbmkfPUsKi"
      },
      "source": [
        "Verify image shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyiKtMQ4UsY6"
      },
      "source": [
        "finger_img_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEj38RWNUsxC"
      },
      "source": [
        "Build the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoJstYwwWi_Z"
      },
      "source": [
        "finger_model = Sequential([\n",
        "  Conv2D(64, 3, activation='relu',\n",
        "         input_shape=finger_img_shape,\n",
        "         kernel_regularizer='l1_l2'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(64, 3, activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(128, 3, activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(128, 3, activation='relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Flatten(),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dense(num_labels, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHuMna9AVf0t"
      },
      "source": [
        "Check the diagram:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqes00PtVf50"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    finger_model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fZMSNgHViP8"
      },
      "source": [
        "## Compile and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqbRLvPgfG6P"
      },
      "source": [
        "Compile:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHSUwlr4ViV9"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "finger_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdepvixhVlVq"
      },
      "source": [
        "Establish training parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6PKIwkQVlcB"
      },
      "source": [
        "steps_per_epoch = train_examples // BATCH_SIZE\n",
        "validation_steps = test_examples // BATCH_SIZE\n",
        "\n",
        "print('steps_per_epoch:', steps_per_epoch)\n",
        "print('validation_steps:', validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSVwM559iPc2"
      },
      "source": [
        "Remove logs and checkpoints:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ri26D97iPlk"
      },
      "source": [
        "!rm -rf tmp/checkpoints\n",
        "!rm -rf logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhUPeAT3i_IR"
      },
      "source": [
        "Prepare TensorBoard callback:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrnhenOuX-xO"
      },
      "source": [
        "log_dir = 'logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTgwoUfpVvuD"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duESsalOVvz2"
      },
      "source": [
        "training_history = finger_model.fit(\n",
        "    train_fingers.repeat(),\n",
        "    validation_data=test_fingers.repeat(),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVpa53NvFnpl"
      },
      "source": [
        "## Visualize Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPU_43J9mSAm"
      },
      "source": [
        "Create a function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzzd0vTXmSL-"
      },
      "source": [
        "def viz_history(training_history):\n",
        "  loss = training_history.history['loss']\n",
        "  val_loss = training_history.history['val_loss']\n",
        "  accuracy = training_history.history['accuracy']\n",
        "  val_accuracy = training_history.history['val_accuracy']\n",
        "  plt.figure(figsize=(14, 4))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(loss, label='Training set')\n",
        "  plt.plot(val_loss, label='Test set', linestyle='--')\n",
        "  plt.legend()\n",
        "  plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(accuracy, label='Training set')\n",
        "  plt.plot(val_accuracy, label='Test set', linestyle='--')\n",
        "  plt.legend()\n",
        "  plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aytTV19bmSTO"
      },
      "source": [
        "Invoke:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHei9o-0mSYm"
      },
      "source": [
        "viz_history(training_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEjwa4sWj0xv"
      },
      "source": [
        "Launch TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zukGvg0cj04T"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-1N1md6m63e"
      },
      "source": [
        "## Close TensorBoard Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9NRBkFJizcg"
      },
      "source": [
        "Use the Global Regular Expression Print (grep) command to find the **pid**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYqQU1apizya"
      },
      "source": [
        "!ps -ef | grep tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwAO4M_Tkr8T"
      },
      "source": [
        "The **pid** is the first process number:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA701oWQm7AH"
      },
      "source": [
        "!kill 10757"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}