{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYYHLHAz1iRI"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "Transfer learning is based on the idea that the feature a network learns for a problem can be reused for a variety of other tasks. In the world, this idea is very natural. When humans learn how to perform a new task, we seldom start from scratch. We carry over all that we have learned in our lifetime. Sometimes this knowledge allows us to quickly learn new stuff. We can often learn from a single training example. But, other times it actually hinders our development. Of course, babies don't learn this way because they don't have the same level of prior knowledge.\n",
        "\n",
        "Resources:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNw5vP76yD8w"
      },
      "source": [
        "For an excellent resource on Transfer Learning models, peruse:\n",
        "\n",
        "https://towardsdatascience.com/an-intuitive-guide-to-deep-network-architectures-65fdc477db41"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co4OvuoiHTwl"
      },
      "source": [
        "# Import **tensorflow** Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrzuqmrgLZdT"
      },
      "source": [
        "Import library and alias it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTSze37cHT1u"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZCOGgMN1iqH"
      },
      "source": [
        "# GPU Hardware Accelerator\n",
        "\n",
        "To vastly speed up processing, we can use the GPU available from the Google Colab cloud service. Colab provides a free Tesla K80 GPU of about 12 GB. Itâ€™s very easy to enable the GPU in a Colab notebook:\n",
        "\n",
        "1.\tclick **Runtime** in the top left menu\n",
        "2.\tclick **Change runtime** type from the drop-down menu\n",
        "3.\tchoose **GPU** from the Hardware accelerator drop-down menu\n",
        "4.\tclick **SAVE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IUXlS6t3klA"
      },
      "source": [
        "Verify that GPU is active:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uUZGsf13j4w"
      },
      "source": [
        "tf.__version__, tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETHXLi-cHlYH"
      },
      "source": [
        "If '/device:GPU:0' is displayed, the GPU is active. If '..' is displayed, the regular CPU is active."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoVyt7eULsly"
      },
      "source": [
        "# Beans Experiment\n",
        "\n",
        "**Beans** is a TensorFlow dataset (TFDS) of bean plant images taken in the field using smartphone cameras. It consists of 3 classes (bean_rust, angular_leaf_spot, healthy). Two of the classes are Angular Leaf Spot and Bean Rust, which are diseases that can befell bean plants. So a bean plant in this dataset is either healthy or afflicted with one of the two diseases. Data was annotated by experts from the National Crops Resources Research Institute (NaCRRI) in Uganda and collected by the Makerere AI research lab.\n",
        "\n",
        "We train beans data with two pre-trained models. In this section, we load and explore the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhTnT7AoLj_Z"
      },
      "source": [
        "Load **beans** as a TFDS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpSgeATF3pt_"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "beans, beans_info = tfds.load(\n",
        "    'beans', with_info=True, as_supervised=True,\n",
        "    try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt8dlKYKLp3b"
      },
      "source": [
        "## Explore the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAv__08kL20J"
      },
      "source": [
        "Display the contents of the **info** object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4erHYLoc8Tpg"
      },
      "source": [
        "beans_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6W1e6RbL80Z"
      },
      "source": [
        "Display splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tep3LU4i9yJJ"
      },
      "source": [
        "beans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeRDf3-2L__C"
      },
      "source": [
        "Simplify processing splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJxqCWMV975Y"
      },
      "source": [
        "train = beans['train']\n",
        "valid = beans['validation']\n",
        "test = beans['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxOHxbNbMEBK"
      },
      "source": [
        "Get labels and number of classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHPJ9rDrE1fu"
      },
      "source": [
        "class_labels = beans_info.features['label'].names\n",
        "num_classes = beans_info.features['label'].num_classes\n",
        "class_labels, num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS8s5Qi7fGoY"
      },
      "source": [
        "Check image sizes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ-qVFSzfGtj"
      },
      "source": [
        "for img, lbl in train.take(10):\n",
        "  print (img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omK55TASfVW_"
      },
      "source": [
        "Athough images are of the same size, we resize to 224 x 224 to increase performance and match the expected size of the pretrained model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjEJWhNcMLrK"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxGK_-kAMNDx"
      },
      "source": [
        "Visualize with **show_examples**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B4TnKdp8nIT"
      },
      "source": [
        "fig = tfds.show_examples(train, beans_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9u5B45cMSLZ"
      },
      "source": [
        "## Reformat Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNTPT7H5MWK5"
      },
      "source": [
        "Resize and process images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEjpij773py3"
      },
      "source": [
        "def preprocess(image, label):\n",
        "  resized_image = tf.image.resize(image, [224, 224])\n",
        "  final_image = tf.keras.applications.xception.\\\n",
        "                preprocess_input(resized_image)\n",
        "  return final_image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7BeGMYpODm7"
      },
      "source": [
        "We resize images to 224 x 224 and run them through Xception's preprocessing input function since we are leveraging an Xception model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EN9W-0HMYfq"
      },
      "source": [
        "## Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp6jn7JLMdRB"
      },
      "source": [
        "Shuffle train data, preprocess, batch, and prefetch train, validate and test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZz1SPJz3p1X"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "shuffle = 250\n",
        "\n",
        "train_ds = train.shuffle(shuffle).\\\n",
        "  map(preprocess).batch(BATCH_SIZE).prefetch(1)\n",
        "valid_ds = valid.map(preprocess).batch(BATCH_SIZE).prefetch(1)\n",
        "test_ds = test.map(preprocess).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nncYhDD3MsWy"
      },
      "source": [
        "Inspect the train tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmLSvT4k7l9H"
      },
      "source": [
        "train_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SMaemo_MvVa"
      },
      "source": [
        "Visualize examples from the train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BRNBIEjA2OS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for img, lbl in train_ds.take(1):\n",
        "  for index in range(9):\n",
        "    plt.subplot(3, 3, index + 1)\n",
        "    plt.imshow(img[index] / 2 + 0.5)\n",
        "    plt.title(class_labels[lbl[index]])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOHbpnVbM1yW"
      },
      "source": [
        "## Model Beans with the Xception Model\n",
        "\n",
        "The Xception model was proposed by Francois Chollet in 2017. **Xception** is an extension of the inception architecture that replaces the standard Inception modules with depthwise Separable Convolutions. Xception often outperforms VGGNet, ResNet, and Inception-v3 models. As a sidenote, Chollet is also the author of Keras. \n",
        "\n",
        "Resources:\n",
        "\n",
        "https://maelfabien.github.io/deeplearning/xception/#\n",
        "\n",
        "https://towardsdatascience.com/review-xception-with-depthwise-separable-convolution-better-than-inception-v3-image-dc967dd42568\n",
        "\n",
        "https://medium.com/analytics-vidhya/image-recognition-using-pre-trained-xception-model-in-5-steps-96ac858f4206#:~:text=Xception%20Model%20is%20proposed%20by,modules%20with%20depthwise%20Separable%20Convolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbxYmadlQCJL"
      },
      "source": [
        "Clear previous models and generate a seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgNsQNluQCWy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nsanCCCrwgi"
      },
      "source": [
        "### Create a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0QNVs3PM4vq"
      },
      "source": [
        "Create a base model from the pre-trained **Xception** model, average input and activate neurons with **softmax** to create the final model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvBNFs14A2Qw"
      },
      "source": [
        "Xception = tf.keras.applications.xception.Xception\n",
        "xception_model = Xception(\n",
        "    weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoSdyAXGfYY4"
      },
      "source": [
        "Load an Xception model pre-trained on ImageNet and exclude the top layer of the network by setting **include_top=False**, which excludes the global average pooling layer and the dense output layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ50WCZ8RzKj"
      },
      "source": [
        "View all the layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1FF7JZyRzRo"
      },
      "source": [
        "xception_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4rjmzVeSXBt"
      },
      "source": [
        "View layer objects:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48pJi7aQSPWd"
      },
      "source": [
        "xception_model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkZvGfA2Sgwm"
      },
      "source": [
        "Get number of layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTL_q7rSg2V"
      },
      "source": [
        "len(xception_model.layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4e_XPQew_2j"
      },
      "source": [
        "Display model as a readable diagram:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Q0E8uXw_9h"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    xception_model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHXeLHRUfStA"
      },
      "source": [
        "Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMGgEgaMdpUg"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,\\\n",
        "                                    GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1LZRpwbfqKJ"
      },
      "source": [
        "Build the final model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3SDj2_0dQ4S"
      },
      "source": [
        "x_model = tf.keras.Sequential([\n",
        "  xception_model,\n",
        "  GlobalAveragePooling2D(),\n",
        "  Dropout(0.5),\n",
        "  Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMWs_dbTO6xf"
      },
      "source": [
        "Since we excluded the top layer of the pre-trained network that has a global average pooling layer and a dense output layer, we must add our own global average pooling layer and a dense output layer with three classes and *softmax* activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5icVcZ-efHUJ"
      },
      "source": [
        "Alternatively, we can build the final model in this form:\n",
        "\n",
        "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\\\n",
        "output = tf.keras.layers.Dense(num_classes, activation='softmax')(avg)\\\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lRRKOWIr126"
      },
      "source": [
        "### Model the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyzZESxaNpvc"
      },
      "source": [
        "Freeze the weights of the pre-trained layers, compile, and train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2ofF3EG4NjR"
      },
      "source": [
        "for layer in xception_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(\n",
        "    lr=0.2, momentum=0.9, decay=0.01)\n",
        "\n",
        "x_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = x_model.fit(\n",
        "    train_ds, validation_data=valid_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPwp2BcxNyH6"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NRm5jrzYenJ"
      },
      "source": [
        "Create a function to visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boS6VGsTYg5n"
      },
      "source": [
        "def visualize(span):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs_range = span\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG1QaK0fYj2O"
      },
      "source": [
        "Invoke:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzayl0KCYj_B"
      },
      "source": [
        "visualize(range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UStcLBxVyX_A"
      },
      "source": [
        "We set a very aggressive learning rate. But loss is not divergent!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JfPmPkKQLtC"
      },
      "source": [
        "### Model Trained Data with Unfrozen Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVUx2TOEQj6d"
      },
      "source": [
        "After we trained the model for a few epochs, validation accuracy is pretty good, but it doesn't get better. This means that the top layers are pretty well trained. Continue training with all the layers unfrozen. We use a **much lower learning rate** to avoid damaging the pre-trained weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRHX6zHpDJJ2"
      },
      "source": [
        "for layer in xception_model.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01, momentum=0.9,\n",
        "    nesterov=True, decay=0.001)\n",
        "\n",
        "x_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = x_model.fit(\n",
        "    train_ds, validation_data=valid_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gzOl8dPRD_l"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ss1ACWzh5do"
      },
      "source": [
        "Visualize performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie0XG_TkXza3"
      },
      "source": [
        "visualize(range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFHwK5YVACFX"
      },
      "source": [
        "Definitely an improvement. For real-world data, set learning rates much, much lower to allow the networks to randomly set optimal weights for the neurons. By setting high learning rates, training time is less but we reduce the ability of networks to randomly adjust neuron weights. A good starting point for learning rate might be in the vicinity of 0.0001!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RbdjI1MRtOG"
      },
      "source": [
        "## Model Beans with the Inception Model\n",
        "\n",
        "**Inception-v3** is a pre-trained convolutional neural network model that is 48 layers deep. It is a version of the network already trained on more than a million images from the ImageNet database. The pre-trained network can classify images into 1000 object categories such as keyboard, mouse, pencil, and many animals.\n",
        "\n",
        "Resources:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3\n",
        "\n",
        "https://medium.com/analytics-vidhya/transfer-learning-using-inception-v3-for-image-classification-86700411251b\n",
        "\n",
        "https://towardsdatascience.com/classify-any-object-using-pre-trained-cnn-model-77437d61e05f#:~:text=Inception%2Dv3%20is%20a%20pre,images%20from%20the%20ImageNet%20database.&text=This%20pre%2Dtrained%20network%20can,%2C%20pencil%2C%20and%20many%20animals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIsk3m-br_QW"
      },
      "source": [
        "### Build a Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPbS7A2NR94l"
      },
      "source": [
        "Create the base model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJlL3psQR9--"
      },
      "source": [
        "inception_v3 = tf.keras.applications.InceptionV3\n",
        "inception_model = inception_v3(\n",
        "    include_top=False, weights='imagenet',\n",
        "    input_shape=(224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5DiuPknTmsY"
      },
      "source": [
        "Clear models and seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ZGGPl5Tmwl"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221XnMlhZSHc"
      },
      "source": [
        "Create the final model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asflw7RCgrFs"
      },
      "source": [
        "i_model = tf.keras.Sequential([\n",
        "  inception_model,\n",
        "  GlobalAveragePooling2D(),\n",
        "  Dropout(0.5),\n",
        "  Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu3dvq6FSuMb"
      },
      "source": [
        "Leave out the last fully connected layer because it is specific to the ImageNet competition. We can use the current shape since include_top is False. Otherwise, the input shape must be (299, 299, 3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmGQJe_mrfSL"
      },
      "source": [
        "Explore base model layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aix3Cj4LrfYs"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    inception_model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crqV--tXsDwB"
      },
      "source": [
        "### Model the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l2YiEKaS2ey"
      },
      "source": [
        "Freeze the weights of the pretrained layers, compile, and train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRMIEzM1S2ks"
      },
      "source": [
        "for layer in inception_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.1)\n",
        "\n",
        "i_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = i_model.fit(\n",
        "    train_ds, validation_data=valid_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-1TZCRDX0p8"
      },
      "source": [
        "Notice that we used the **RMSprop** loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4cnI3VssK-D"
      },
      "source": [
        "### Visualize Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7CZoM-xhnqE"
      },
      "source": [
        "Visualize performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uUu2UjGiiAk"
      },
      "source": [
        "visualize(range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKQB2cWAy3Uf"
      },
      "source": [
        "We set an aggressive learning rate. Although loss is erratic, it still is not divergent. As an experiment, set a much lower learning rate. Training time will be increased, but loss will be less divergent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou0BXOwQsPeZ"
      },
      "source": [
        "### Model Trained Data with Unfrozen Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wbhk7OfTQOt"
      },
      "source": [
        "Let's see if we can squeeze out more performance by unfreezing all layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEP8mrczTQWE"
      },
      "source": [
        "for layer in inception_model.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)\n",
        "\n",
        "i_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = i_model.fit(\n",
        "    train_ds, validation_data=valid_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7shA25wv0bh"
      },
      "source": [
        "We use a **much lower learning rate** to avoid damaging the pretrained weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNMantMLsZEG"
      },
      "source": [
        "### Visualize Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7zAIUUoWSyf"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrQla0kukoZr"
      },
      "source": [
        "visualize(range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf1vKO6ZWuZP"
      },
      "source": [
        "We are able to increase performance and somewhat smooth out loss divergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMgaDtNHHnh2"
      },
      "source": [
        "## Generalize on Unseen Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLoGe4EpH975"
      },
      "source": [
        "Generalize on the unseen test dataset for the Xception model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8okng9QH-Bj"
      },
      "source": [
        "x_model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06oezl3tHyPT"
      },
      "source": [
        "Generalize on the unseen test dataset for the Inception model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N-nHrAPHnpo"
      },
      "source": [
        "i_model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxKVJGfIVzZb"
      },
      "source": [
        "# Stanford Dogs Experiment\n",
        "\n",
        "The **Stanford Dogs** dataset contains images of 120 breeds of dogs from around the world. It has been built using images and annotation from ImageNet for the task of fine-grained image categorization. The dataset contains 20,580 images split into 12,000 training images and 8,580 testing images. Class labels and bounding box annotations are provided for all 12,000 images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS5SKaoyw5Fd"
      },
      "source": [
        "## Model Stanford Dogs with the MobileNet Model\n",
        "\n",
        "MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embedding, and segmentation similar to how other popular large scale models such as Inception.\n",
        "\n",
        "The **MobileNet V2** model was developed at Google. It is pre-trained on the ImageNet dataset, which is a large dataset consisting of 1.4 million images and 1,000 classes. **ImageNet** is a research training dataset with a wide variety of categories like jackfruit and syringe. Its base knowledge helps us classify dogs from our specific dataset.\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcXncMpBzBo9"
      },
      "source": [
        "Load the train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYnobnbkdaWG"
      },
      "source": [
        "train_pups, dogs_info = tfds.load(\n",
        "    'stanford_dogs', with_info=True,\n",
        "    as_supervised=True, try_gcs=True,\n",
        "    split='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BGmvweDPs9z"
      },
      "source": [
        "Get metadata:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Kh1vcKPtDc"
      },
      "source": [
        "dogs_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlY5nlrAzI6T"
      },
      "source": [
        "Now that we know the splits, load the validation and test sets:set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JYB80tGPP8r"
      },
      "source": [
        "(validation_pups, test_pups) = tfds.load(\n",
        "    'stanford_dogs',\n",
        "    split=['test[:50%]', 'test[50%:]'],\n",
        "    as_supervised=True, try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wb4-aJh7TRj"
      },
      "source": [
        "## Visualize Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m60BxQu7nfVW"
      },
      "source": [
        "Create a function to get the named label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpBBJFkFm4U-"
      },
      "source": [
        "get_name = dogs_info.features['label'].int2str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akuH8bS4nzPn"
      },
      "source": [
        "By trial and error, we got all integer labels and converted them to named ones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM7iuAwmk773"
      },
      "source": [
        "lbls = []\n",
        "for image, label in train_pups.take(464):\n",
        "  lbls.append(get_name(label))\n",
        "set_lbl = set(lbls)\n",
        "len(set_lbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3jm89NKs0Z0"
      },
      "source": [
        "We have all of the labels in a list!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulQTC-79pWE7"
      },
      "source": [
        "Grab some images and labels for visualization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWacOO7OpWLR"
      },
      "source": [
        "img, lbl = [], []\n",
        "for image, label in train_pups.take(9):\n",
        "  img.append(image)\n",
        "  lbl.append(get_name(label)[10:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7TNDP0xtHvO"
      },
      "source": [
        "Display the first one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lSZGo8LqM-m"
      },
      "source": [
        "lbl[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCM5b-FF7Uyb"
      },
      "source": [
        "Display some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFmtqhJY6Zdr"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for index in range(9):\n",
        "  plt.subplot(3, 3, index + 1)\n",
        "  plt.imshow(img[index])\n",
        "  plt.title(lbl[index])\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whqtOQHh8IHz"
      },
      "source": [
        "Display some examples with **show_examples**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPwBmfDIcgh8"
      },
      "source": [
        "fig = tfds.show_examples(train_pups, dogs_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz7OvOWy7dkc"
      },
      "source": [
        "## Check Image Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFG4_JO57l2U"
      },
      "source": [
        "Display some example shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7lCRpfF7drA"
      },
      "source": [
        "for img, lbl in train_pups.take(10):\n",
        "  print (img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlYc_QSY7pKT"
      },
      "source": [
        "Since images are of varying sizes, we must resize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIug-4CLzKtL"
      },
      "source": [
        "## Explore Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSFBInNMzP-B"
      },
      "source": [
        "Get number of classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-9kSDreVzvL"
      },
      "source": [
        "class_labels = dogs_info.features['label']\n",
        "num_breeds = dogs_info.features['label'].num_classes\n",
        "class_labels, num_breeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-I9g5llMpdG"
      },
      "source": [
        "## Prepare Data and Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz4CtJQEMwT4"
      },
      "source": [
        "Create variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfFTwvOgIiR5"
      },
      "source": [
        "IMG_LEN = 224\n",
        "IMG_SHAPE = (IMG_LEN,IMG_LEN,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vb_0hTXMy3o"
      },
      "source": [
        "Create a function to preprocess:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF3E8baPM3mP"
      },
      "source": [
        "def preprocess(img, lbl):\n",
        "  resized_image = tf.image.resize(img, [IMG_LEN, IMG_LEN])\n",
        "  final_image = tf.keras.applications.mobilenet.preprocess_input(\n",
        "      resized_image)\n",
        "  label = tf.one_hot(lbl, num_breeds)\n",
        "  return final_image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOCmCjl-M_Wf"
      },
      "source": [
        "Function resizes and preprocesses. It also encodes labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYCyNLbcM5tX"
      },
      "source": [
        "Create a function to build the pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw60KTsFIiUZ"
      },
      "source": [
        "def prepare(dataset, batch_size=None, shuffle_size=None):\n",
        "  ds = dataset.map(preprocess, num_parallel_calls=4)\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  if batch_size:\n",
        "    ds = ds.batch(batch_size)\n",
        "  if shuffle_size:\n",
        "    ds = ds.shuffle(shuffle_size)   \n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqgWhZogzrFM"
      },
      "source": [
        "Build the pipeline with batch size of 32 and shuffle size of 1,000:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d05RXRDMQHdK"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_SIZE = 1000\n",
        "\n",
        "train_dogs = prepare(train_pups, batch_size=BATCH_SIZE,\n",
        "                     shuffle_size=SHUFFLE_SIZE)\n",
        "validation_dogs = prepare(validation_pups, batch_size=32)\n",
        "test_dogs = prepare(test_pups, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjY0pob0z0Q2"
      },
      "source": [
        "Inspect training tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwg7JO0cfnEB"
      },
      "source": [
        "train_dogs, validation_dogs, test_dogs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt4eT1d30URf"
      },
      "source": [
        "## Model Data\n",
        "\n",
        "For a nice tutorial on tranfer learning with stanford dogs, peruse:\n",
        "\n",
        "https://www.angioi.com/dog-breed-classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM2bzESY0r2g"
      },
      "source": [
        "Create the base model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLtbhxGHfnIv"
      },
      "source": [
        "mobile_v2 = tf.keras.applications.MobileNetV2\n",
        "mobile_model = mobile_v2(\n",
        "    input_shape=IMG_SHAPE, include_top=False,\n",
        "    weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlFqvX8-thqn"
      },
      "source": [
        "Explore the base model layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmBQXlPtthyp"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    mobile_model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE3YIr7Z0xC_"
      },
      "source": [
        "## Create and Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6GKGxkr0yt_"
      },
      "source": [
        "Clear previous models and generate a seed for reproducibility of results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ovctdcGel73"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4HisYaG09YJ"
      },
      "source": [
        "Verify number of classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MffQeFtuX40"
      },
      "source": [
        "num_breeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3OQIQdE1CrI"
      },
      "source": [
        "Create a simple feedforward network and add the pretrained model to the first layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2FigJGtel_K"
      },
      "source": [
        "mobile_model.trainable = False\n",
        "\n",
        "sd_model = tf.keras.Sequential([\n",
        "  mobile_model,\n",
        "  GlobalAveragePooling2D(),\n",
        "  Dropout(0.5),\n",
        "  Dense(num_breeds, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR8sl_OYR6H3"
      },
      "source": [
        "Notice that we freeze the top layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYUe2mZSOMuR"
      },
      "source": [
        "Since we are training **many** more images and **many** more classes, training time is much longer. So be patient. Don't be concerned if your computer *craps out*. It is not an error. More RAM is needed. We use Colab Pro and don't seem to have an issue.\n",
        "\n",
        "Compile and train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VilQ53hOQVGj"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "sd_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adamax(learning_rate=0.005),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "\n",
        "history = sd_model.fit(\n",
        "    train_dogs, epochs=EPOCHS, validation_data=validation_dogs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrRD_XFFxw8G"
      },
      "source": [
        "We set a faster learning rate and got pretty good results. By setting a low learning rate, training progresses slowly as we are making very tiny updates to the weights in the network. However, if learning rate is set too high, it can cause undesirable divergent behavior in the loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te9sS5fIjXpK"
      },
      "source": [
        "## Visualize Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-yyX0ngOa-J"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4MhbcbKuiZZ"
      },
      "source": [
        "visualize(range(EPOCHS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl9_l1YfOoQ6"
      },
      "source": [
        "Not bad! Accuracy is over 80% in our experiment with 10 epochs. If we look at the top-5 predictions, the chance of guessing the correct breed jumps to over 97%. Setting a less aggressive learning rate mitigates loss divergence. Loss is somewhat divergent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZId0Xow6qPNV"
      },
      "source": [
        "Visualize Top 5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eIjYWxRPvuk"
      },
      "source": [
        "acc = history.history['top_k_categorical_accuracy']\n",
        "val_acc = history.history['val_top_k_categorical_accuracy']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Top 5 Training and Validation Accuracy')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI1N5PA9q1CQ"
      },
      "source": [
        "Not bad! We get over 80% accuracy for breed detection. If we look at the top-5 predictions, the chance of guessing the correct breed jumps to over 97%! Since the dataset is large and complex, we show that using pre-trained models can have real-world use cases. Also it is amazing that we can build such a powerful model in just a few lines of code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNgATmQCwOkd"
      },
      "source": [
        "## Model Trained Data with Unfrozen Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdOJLsHinU6N"
      },
      "source": [
        "After we trained the model for ten epochs, validation accuracy is pretty good, but its trajectory is not increasing. So the top layers are pretty well trained. Unfreeze the top layers and continute training. We use a **much lower learning rate** to avoid damaging the pre-trained weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZI4ZwGdnu1n"
      },
      "source": [
        "mobile_model.trainable = True\n",
        "\n",
        "sd_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adamax(0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "\t\t\t  \n",
        "history = sd_model.fit(\n",
        "    train_dogs, epochs=3,\n",
        "    validation_data=validation_dogs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hCy2suWwFgq"
      },
      "source": [
        "We use a **much lower learning rate** to avoid damaging the pretrained weights. Unfreezing the layers, doesn't seem to improve performance. But we only run for three epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acAfGXmkqAQ9"
      },
      "source": [
        "## Visualize Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcKmIkqmqETY"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cweUT9edw04Y"
      },
      "source": [
        "visualize(range(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrqN8-Zoayu7"
      },
      "source": [
        "Visualize Top:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj_XVkP1qKh1"
      },
      "source": [
        "acc = history.history['top_k_categorical_accuracy']\n",
        "val_acc = history.history['val_top_k_categorical_accuracy']\n",
        "\n",
        "epochs_range = range(3)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Top 5 Training and Validation Accuracy')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIFKhiCFdXbe"
      },
      "source": [
        "## Generalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D9HsaMfdY9d"
      },
      "source": [
        "Generalize from unseen data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diebIXSwdXgW"
      },
      "source": [
        "sd_model.evaluate(test_dogs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JASTZm47yPIq"
      },
      "source": [
        "# Flowers Experiment\n",
        "\n",
        "Load flowers as TFRecords and use a pre-trained model for learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9B0UzL9sLYa"
      },
      "source": [
        "## Read Flowers as TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWjAGzTDsXBi"
      },
      "source": [
        "Read TFRecord files from GCS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3pUVOiosLd-"
      },
      "source": [
        "piece1 = 'gs://flowers-public/'\n",
        "piece2 = 'tfrecords-jpeg-192x192-2/*.tfrec'\n",
        "TFR_GCS_PATTERN = piece1 + piece2\n",
        "tfr_filenames = tf.io.gfile.glob(TFR_GCS_PATTERN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyGHdps-sfM_"
      },
      "source": [
        "## Create Data Splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgJPLPYOsqUR"
      },
      "source": [
        "Set parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PQnh1cksfUJ"
      },
      "source": [
        "IMAGE_SIZE = [192, 192]\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "SHUFFLE_SIZE = 100\n",
        "EPOCHS = 5\n",
        "VALIDATION_SPLIT = 0.19\n",
        "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EfwnuZVsfZQ"
      },
      "source": [
        "Create splits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIJmSQiksffP"
      },
      "source": [
        "split = int(len(tfr_filenames) * VALIDATION_SPLIT)\n",
        "training_filenames = tfr_filenames[split:]\n",
        "validation_filenames = tfr_filenames[:split]\n",
        "print ('Splitting dataset into {} training files and {}'\n",
        "       'validation files'.\\\n",
        "       format(\n",
        "           len(tfr_filenames), len(training_filenames),\n",
        "           len(validation_filenames)), end = ' ')\n",
        "print ('with a batch size of {}.'.format(BATCH_SIZE))\n",
        "\n",
        "validation_steps = int(3670 // len(tfr_filenames) *\\\n",
        "                       len(validation_filenames)) // BATCH_SIZE\n",
        "steps_per_epoch = int(3670 // len(tfr_filenames) *\\\n",
        "                      len(training_filenames)) // BATCH_SIZE\n",
        "print ('There are {} batches per training epoch and {} '\\\n",
        "       'batches per validation run.'\\\n",
        "       .format(BATCH_SIZE, steps_per_epoch, validation_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTdqsAW1tKW9"
      },
      "source": [
        "## Create Functions to Load and Process TFRecord Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvycMOoqBg51"
      },
      "source": [
        "Demonstrate one-hot encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9IENZkC3Zgk"
      },
      "source": [
        "named_lbl = 'sunflowers'\n",
        "indx = CLASSES.index(named_lbl)\n",
        "encode = tf.one_hot([indx], 5)\n",
        "one_hot = encode[0].numpy()\n",
        "print ('encoded label:', one_hot)\n",
        "pos = tf.math.argmax(one_hot).numpy()\n",
        "print ('integer label:', pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-wJiM4HtOew"
      },
      "source": [
        "Create a function to parse a TFRecord file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACXhn88BtKdo"
      },
      "source": [
        "def read_tfrecord(example):\n",
        "  features = {\n",
        "      'image': tf.io.FixedLenFeature([], tf.string),\n",
        "      'class': tf.io.FixedLenFeature([], tf.int64)\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "  image = tf.cast(image, tf.float32) / 255.0 \n",
        "  image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "  class_label = example['class']\n",
        "  one_hot = tf.one_hot(class_label, 5)\n",
        "  return image, one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us8QCc66tKjx"
      },
      "source": [
        "Create a function to load TFRecord files as tf.data.Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUTX7lQ9tKq7"
      },
      "source": [
        "def load_dataset(filenames):\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic = False\n",
        "  dataset = tf.data.TFRecordDataset(\n",
        "      filenames, num_parallel_reads=AUTO)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meIQLyTbtXFU"
      },
      "source": [
        "Create a function to build an input pipeline from TFRecord files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e6bCzkotXKz"
      },
      "source": [
        "def get_batched_dataset(filenames, train=False):\n",
        "  dataset = load_dataset(filenames)\n",
        "  dataset = dataset.cache()\n",
        "  if train:\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0T_EV6rtXP-"
      },
      "source": [
        "## Create Train and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBynj2ddtgOA"
      },
      "source": [
        "Instantiate the datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYP5H-bjtXVW"
      },
      "source": [
        "training_dataset = get_batched_dataset(\n",
        "    training_filenames, train=True)\n",
        "validation_dataset = get_batched_dataset(\n",
        "    validation_filenames, train=False)\n",
        "training_dataset, validation_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAQigH11tXaM"
      },
      "source": [
        "Display an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaSoJSDAtXfV"
      },
      "source": [
        "for img, lbl in training_dataset.take(1):\n",
        "  plt.axis('off')\n",
        "  label = tf.math.argmax(lbl[0]).numpy()\n",
        "  plt.title(CLASSES[label])\n",
        "  fig = plt.imshow(img[0])\n",
        "  tfr_flower_shape = img.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HYFaS2BtxsF"
      },
      "source": [
        "## Model Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnVMMevlySAi"
      },
      "source": [
        "Create a list of pre-trained models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpXcUvloySGQ"
      },
      "source": [
        "ptm =\\\n",
        "  [tf.keras.applications.MobileNetV2,\n",
        "   tf.keras.applications.VGG16,\n",
        "   tf.keras.applications.MobileNet,\n",
        "   tf.keras.applications.xception.Xception,\n",
        "   tf.keras.applications.InceptionV3,\n",
        "   tf.keras.applications.ResNet50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XicEXJnRuLWN"
      },
      "source": [
        "Choose any of the pre-trained models by index. We use Xception in this use case:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFYH8TbF55r2"
      },
      "source": [
        "pre_trained_model = ptm[3](\n",
        "    weights='imagenet', include_top=False,\n",
        "    input_shape=[*IMAGE_SIZE, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDEjRfEM7ghp"
      },
      "source": [
        "Clear and seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSBtlqhA7gvg"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8stm4fmeuAL9"
      },
      "source": [
        "Create the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv5NhTpguASe"
      },
      "source": [
        "pre_trained_model.trainable = True\n",
        "\n",
        "flower_model = tf.keras.Sequential([\n",
        "  pre_trained_model,\n",
        "  GlobalAveragePooling2D(),\n",
        "  Dense(5, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUFCIdeyuAk6"
      },
      "source": [
        "We use the Xception pre-trained model. We drop the ImageNet-specific top layers with include_top=false and a max pooling and a softmax layer to predict the 5 flower classes. We also unfreeze all of the top layers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OayRXY73uAYT"
      },
      "source": [
        "## Compile and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XGw7CvCvI0Q"
      },
      "source": [
        "Compile:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMvc87psvI6f"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "flower_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4f8HqagPw4V"
      },
      "source": [
        "The initial learning rate is often the single most important hyperparameter. If one can tune only one hyperparameter, learning rate is the one worth tuning. However, the **Adam** optimizer automatically tunes learning rate!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjEmfYsFO36w"
      },
      "source": [
        "By training with a small learing rate, the model learns a more optimal or even a globally optimal set of weights. However, training takes significantly longer. When the learning rate is too large, gradient descent can inadvertently increase rather than decrease the training error. The idea is to allow a neural network to randomly adjust its weights. Lower learning rates increase randomization. Higher ones decrease randomization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsAQJ04ivI_9"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsUh0znPwlmu"
      },
      "source": [
        "history = flower_model.fit(\n",
        "    training_dataset, epochs=EPOCHS,\n",
        "    verbose=1, steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps, \n",
        "    validation_data=validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSKx4sRE7zkc"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X91W0pI770Hz"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYCtZIwU78jC"
      },
      "source": [
        "visualize(range(EPOCHS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge2z6DSHSCvb"
      },
      "source": [
        "## Generalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1SV9rgeSOLk"
      },
      "source": [
        "Generalize on the validation set because we didn't split out a test one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG3_XScMSC5q"
      },
      "source": [
        "flower_model.evaluate(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y24AU0hS7By"
      },
      "source": [
        "# Rock Paper Scissors Experiment\n",
        "\n",
        "The data contains images of hands playing the rock, paper, scissor game."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMs3z3v4U6Y4"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFGAMvULS8lV"
      },
      "source": [
        "Load the train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhR71gXlS7Ht"
      },
      "source": [
        "train_digits, rps_info = tfds.load(\n",
        "    'rock_paper_scissors', with_info=True,\n",
        "    split='train', as_supervised=True,\n",
        "    try_gcs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emP-Iw92bkFW"
      },
      "source": [
        "Load the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZxBTWJ5S7ep"
      },
      "source": [
        "test_digits = tfds.load(\n",
        "    'rock_paper_scissors',  try_gcs=True,\n",
        "    as_supervised=True, split='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLgYEnSS7OM"
      },
      "source": [
        "Display metadata:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsdOXasTS7UE"
      },
      "source": [
        "rps_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CltOk4erW26b"
      },
      "source": [
        "Inspect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdV9PS15W3CW"
      },
      "source": [
        "for image, label in train_digits.take(5):\n",
        "  print (image.shape, label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_hMfaiqV9uD"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC24BXS4WqJS"
      },
      "source": [
        "Visualize examples from the train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5PM46AOVlZl"
      },
      "source": [
        "fig = tfds.show_examples(train_digits, rps_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoVDzCpYVlUI"
      },
      "source": [
        "## Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuhWv7bzVlfK"
      },
      "source": [
        "Create a function to process images and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzJ5B5ckVlkX"
      },
      "source": [
        "def process_digits(image, label):\n",
        "  resized_image = tf.image.resize(image, [224, 224])\n",
        "  final_image = tf.keras.applications.xception.\\\n",
        "                preprocess_input(resized_image)\n",
        "  one_hot = tf.one_hot(label, 3)\n",
        "  return final_image, one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1wDOCHdVzYz"
      },
      "source": [
        "Build the pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKlfPWvQVzmn"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "shuffle = 250\n",
        "\n",
        "train_fingers = train_digits.shuffle(shuffle).\\\n",
        "  map(process_digits).batch(BATCH_SIZE).prefetch(1)\n",
        "test_fingers = test_digits.map(process_digits).\\\n",
        "  batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuGdBMeuiLgU"
      },
      "source": [
        "## Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6svvkHxVq4k"
      },
      "source": [
        "Create the base model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5lKomRIYrjn"
      },
      "source": [
        "Xception = tf.keras.applications.xception.Xception\n",
        "xception_model = Xception(\n",
        "    weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh08AGk5Vrl7"
      },
      "source": [
        "Clear and seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ5x_GvjVrtP"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjtbIg3gZ2Yl"
      },
      "source": [
        "Create the final model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ8ONxHnZ2gB"
      },
      "source": [
        "pre_trained_model.trainable = True\n",
        "\n",
        "fingers_model = tf.keras.Sequential([\n",
        "  xception_model,\n",
        "  GlobalAveragePooling2D(),\n",
        "  Dense(3, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUr9ox7IiTr8"
      },
      "source": [
        "## Compile and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YuAUW-yZ-4t"
      },
      "source": [
        "Compile:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmLbtypQZ--4"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "fingers_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47sTNUqcaDBP"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuKophruaDG4"
      },
      "source": [
        "history = fingers_model.fit(\n",
        "    train_fingers, epochs=10,\n",
        "    validation_data=test_fingers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taVSVxMBzAwx"
      },
      "source": [
        "## Visualize Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNn-wmn8zE7k"
      },
      "source": [
        "Visualize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0G_dUatzA2x"
      },
      "source": [
        "visualize(range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4xU80rFzBrg"
      },
      "source": [
        "## Generalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtcJH-ubzVPN"
      },
      "source": [
        "Generalize on test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWTMz5KwzBy4"
      },
      "source": [
        "fingers_model.evaluate(test_fingers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snGrcYkm4TRS"
      },
      "source": [
        "# Tips and Concepts\n",
        "\n",
        "For additional tips to tune transfer learning models, peruse:\n",
        "\n",
        "https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b\n",
        "\n",
        "For a comprehensive take on the subject, peruse:\n",
        "\n",
        "https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a"
      ]
    }
  ]
}