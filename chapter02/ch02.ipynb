{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceXcxnFyONlJ"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "More data typically increases model performance. So, what do we do if we have small amounts of image training data and cannot collect more? One popular method is data augmentation.\n",
        "\n",
        "**Data augmentation** is the increase of an existing training dataset's size and diversity without the requirement of manually collecting any new data. The approach generates additional training data from existing examples by augmenting them using random transformations that yield believable-looking images, which exposes the model to more aspects of the data and helps it generalize better.\n",
        "\n",
        "We train a deep learning model to tune its parameters so it can effectively map a particular input (e.g., an image) to some output (e.g., a label). The goal is to find the sweet spot where the model’s loss is low, which happens when your parameters are tuned in the right way.\n",
        "\n",
        "Specifically, data augmentation is acquired by performing a series of random preprocessing transformations to existing data such as horizontal and vertical flipping, skewing, cropping, shearing, zooming in and out, and rotating. Collectively, augmented data is able to simulate a variety of subtly different data points as opposed to just duplicating the same data. The subtle differences of the augmented images should (hopefully) be enough to help train a more robust model.\n",
        "\n",
        "Data augmentation can also mitigate overfitting. Overfitting generally occurs when there are a small number of training examples. By generating additional training data from existing examples, we may mitigate overfitting.\n",
        "\n",
        "General resource:\n",
        "\n",
        "https://www.charterglobal.com/image-data-augmentation-and-ai/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYRL40lsIkib"
      },
      "source": [
        "# Import **tensorflow** Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqTIOQ-uIkoa"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnIrKGSX0Zkx"
      },
      "source": [
        "# GPU Hardware Accelerator\n",
        "\n",
        "To vastly speed up processing, we can use the GPU available from the Google Colab cloud service. Colab provides a free Tesla K80 GPU of about 12 GB. It’s very easy to enable the GPU in a Colab notebook:\n",
        "\n",
        "1.\tclick **Runtime** in the top left menu\n",
        "2.\tclick **Change runtime** type from the drop-down menu\n",
        "3.\tchoose **GPU** from the Hardware accelerator drop-down menu\n",
        "4.\tclick **SAVE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2S6yy-suUut"
      },
      "source": [
        "Verify that GPU is active:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRLvQJxzuiph"
      },
      "source": [
        "tf.__version__, tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ElVm1Ji06To"
      },
      "source": [
        "If '/device:GPU:0' is displayed, the GPU is active. If '..' is displayed, the regular CPU is active."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSKRjAyvgPOH"
      },
      "source": [
        "# Work with Flowers Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIQDmwoXZQlA"
      },
      "source": [
        "Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFUN0L9OXHi3"
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls_0AF3nZS8c"
      },
      "source": [
        "Download data with **tf.keras.utils.get_file** utility:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb3bjQ1IXHln"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "url1 = 'https://storage.googleapis.com/download.tensorflow.org/'\n",
        "url2 = 'example_images/flower_photos.tgz'\n",
        "dataset_url = url1 + url2\n",
        "\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='flower_photos', \n",
        "                                   untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZk11gyZk0d5"
      },
      "source": [
        "## Split Data\n",
        "\n",
        "Load images off disk using **tf.keras.preprocessing.image_dataset_from_directory** utility into train and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOsCqk0Lk5TX"
      },
      "source": [
        "Set parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JxGf0OEk5kI"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mhci8_XBdhb"
      },
      "source": [
        "Batch size is set to 32. Since images have different shapes, images are resized to 180 x 180 for model consumption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSnjSMelk56N"
      },
      "source": [
        "### Create Train and Test Sets\n",
        "\n",
        "The **tf.keras.preprocessing.image_dataset_from_directory** utiltity reads the data from a directory. It then splits, seeds, resizes, and batches the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikofMoNCVFMu"
      },
      "source": [
        "Create the train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2Em0Nhk5-5"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.19,\n",
        "  subset='training',\n",
        "  seed=0,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fETf4TVsVI2z"
      },
      "source": [
        "Set **validation_split=0.19** and **subset='training'**, to get 81% train data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU6RltvEA2by"
      },
      "source": [
        "Create the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj088QYblHNA"
      },
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.19,\n",
        "  subset='validation',\n",
        "  seed=0,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JfjHQ1VVdkF"
      },
      "source": [
        "Set **validation_split=0.19** and **subset='validation'**, to get 19% test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAHOUpdgfavl"
      },
      "source": [
        "## Inspect Train Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31smeoVGA8q5"
      },
      "source": [
        "Take an example batch and display image shape and label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tEWYNv8fa1C"
      },
      "source": [
        "for images, labels in train_ds.take(1):\n",
        "  print ('image shape:', images.shape)\n",
        "  print ('labels:', labels.numpy())\n",
        "  print ('number of labels in a batch:', len(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9LMIED9BKQZ"
      },
      "source": [
        "As expected, we have 32 180 x 180 images in the first batch. We also have 32 corresponding labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHyB6EqJ5nml"
      },
      "source": [
        "## Get Number of Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqTRyCANCNV0"
      },
      "source": [
        "Display number of labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BuhHWG44FBA"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "num = len(class_names)\n",
        "num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzf2u1kR0wIc"
      },
      "source": [
        "## Create Scale Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXD7mkKgCQyT"
      },
      "source": [
        "Create a function to scale images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHI2XDOm0wNu"
      },
      "source": [
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255.0\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8W-BmIm0Zys"
      },
      "source": [
        "## Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxlZSendLem9"
      },
      "source": [
        "Scale train and test sets. Shuffle train data, cache, ahd prefetch train and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FPKi5wiLh48"
      },
      "source": [
        "SHUFFLE_SIZE = 100\n",
        "\n",
        "train_fds = train_ds.map(scale).shuffle(SHUFFLE_SIZE).\\\n",
        "            cache().prefetch(1)\n",
        "test_fds = test_ds.map(scale).cache().prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH7QLrdACW6G"
      },
      "source": [
        "<!-- Use AUTOTUNE: -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3o2nGVNvWb_"
      },
      "source": [
        "# Apply Data Augmentation with Preprocessing Layers\n",
        "\n",
        "Apply data augmentation with experimental Keras Preprocessing Layers. We include the layers inside a model like other layers. Let's augment images by randomly flipping horizonatally, rotating, zooming, and translating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Std8fJFHvWg3"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing\\\n",
        "  import RandomFlip\n",
        "from tensorflow.keras.layers.experimental.preprocessing\\\n",
        "  import RandomRotation\n",
        "from tensorflow.keras.layers.experimental.preprocessing\\\n",
        "  import RandomZoom\n",
        "from tensorflow.keras.layers.experimental.preprocessing\\\n",
        "  import RandomTranslation\n",
        "\n",
        "\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "   RandomFlip('horizontal'),\n",
        "   RandomRotation(0.1),\n",
        "   RandomZoom(0.1),\n",
        "   RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da_CiKbC66au"
      },
      "source": [
        "Resources:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/data_augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OtD2hTx0K71"
      },
      "source": [
        "## Display an Augmented Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pi0P2ejGi7z"
      },
      "source": [
        "Here is what happens when applying data augmentation to the same image several times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv-QnQ4J0LC8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_fds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEqPWcOv7M9z"
      },
      "source": [
        "## Clear Models and Generate Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zidcuvxIGlAr"
      },
      "source": [
        "Clear all previous models and generate a seed for reproducibility:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x13vNeR73rMx"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-ryjPrs7Qfq"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKE4fO1ZGrkk"
      },
      "source": [
        "Import requisite libraries to build the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQcfOLiR35hc"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8rWctnY7VCz"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEaN7J10Gw2c"
      },
      "source": [
        "Build a multi-layered CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWQ69R7q3rPp"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  data_augmentation,\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPooling2D(),\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPooling2D(),\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPooling2D(),\n",
        "  Flatten(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dropout(0.5),\n",
        "  Dense(num)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAg4gEO97YbG"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaLaayy3G2CF"
      },
      "source": [
        "Compile with SparseCategoricalCrossentropy(from_logits=True):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckMWrL2s3rR5"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAxYYxLa7bE2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9MGyviQG7ME"
      },
      "source": [
        "Train model for three epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v95PCRbt3rUy"
      },
      "source": [
        "history = model.fit(\n",
        "    train_fds,\n",
        "    validation_data=test_fds,\n",
        "    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdTwv3rc7dBT"
      },
      "source": [
        "# Apply Data Augmentation Directly on Images\n",
        "\n",
        "Instead of creating a training model with an augmentation layer, we can perform transformations directly on images.\n",
        "\n",
        "General resource:\n",
        "\n",
        "https://medium.com/mlait/image-data-augmentation-image-processing-in-tensorflow-part-2-b77237256df0\n",
        "\n",
        "TensorFlow resource:\n",
        "\n",
        "https://towardsdatascience.com/tensorflow-image-augmentation-on-gpu-bf0eaac4c967"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHIn4wEzRiIN"
      },
      "source": [
        "Grab some images from the training set we created earlier in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHQXUzNuRiOv"
      },
      "source": [
        "for batch_images, _ in train_fds.take(1):\n",
        "  print ('image shape:', batch_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArUxDyQQWNcR"
      },
      "source": [
        "Since a training set of images was already created earlier in the notebook, just grab the first batch. Now, we have a batch of 32 images with which to play."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW2tKpqy00MT"
      },
      "source": [
        "## Set Index\n",
        "\n",
        "Since batch size is 32, we can set the value from 0 to 31."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUrGnPwVY0g5"
      },
      "source": [
        "indx = 0\n",
        "indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gopDAIdcWpYa"
      },
      "source": [
        "We set the index to grab the first image from the batch. Change the index value (between 0 and 31) to display different images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfBNW9d0Xxk3"
      },
      "source": [
        "Image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quJuRCS0Xxse"
      },
      "source": [
        "our_image = batch_images[indx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luAlcogaUkZ9"
      },
      "source": [
        "## Show an Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPNbJr1BWwuf"
      },
      "source": [
        "Display the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLKdkwVeUBQ5"
      },
      "source": [
        "plt.imshow(our_image)\n",
        "plt.axis('off')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9eMpPN713qr"
      },
      "source": [
        "## Create Functions to Show Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M48OcX0o8TTL"
      },
      "source": [
        "Show original and modified image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83ThTFXPXjA9"
      },
      "source": [
        "def show(original_img, trans_img):\n",
        "  f = plt.figure(figsize=(6, 6))\n",
        "  f.add_subplot(1,2,1)\n",
        "  plt.imshow(original_img)\n",
        "  plt.axis('off')\n",
        "  f.add_subplot(1,2,2)\n",
        "  plt.imshow(trans_img)\n",
        "  plt.axis('off')\n",
        "  plt.show(block=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwts1hDD8ZJC"
      },
      "source": [
        "Show several transformations of an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ugDdVqXYvTq"
      },
      "source": [
        "def show_images(img, indx, trans, p1=None, p2=None, b=False):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    if not b:\n",
        "      new_img = trans(img[indx])\n",
        "    elif p2==None:\n",
        "      new_img = trans(img[indx], p1)\n",
        "      new_img = np.clip(new_img, 0, 1)\n",
        "    else:\n",
        "      new_img = trans(img[indx], p1, p2)\n",
        "      new_img = np.clip(new_img, 0, 1)\n",
        "    plt.imshow(new_img)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kO_4yfvtF0k"
      },
      "source": [
        "## Demonstrate Examples\n",
        "\n",
        "Let's demonstrate how to augment directly on images.\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/image/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88j1vNXC0v_c"
      },
      "source": [
        "## Crop an Image\n",
        "\n",
        "To **crop** an image, remove or adjust its outside edges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSlphiHH06Q7"
      },
      "source": [
        "Crop:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEHahQ-IPcXP"
      },
      "source": [
        "new_image = tf.image.random_crop(our_image, [120, 120, 3])\n",
        "new_image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buUYEkte2N1W"
      },
      "source": [
        "Show original and modified image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Q9l6bdQIfy"
      },
      "source": [
        "show(our_image, new_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLcLB18IpbJS"
      },
      "source": [
        "Since the transformation is random, the image is cropped randomly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9863TZAo2d1"
      },
      "source": [
        "show_images(batch_images, indx, tf.image.random_crop,\n",
        "            [120, 120, 3], b=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9PTRU_n6goE"
      },
      "source": [
        "Centrally crop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rPU9q3_M2vl"
      },
      "source": [
        "new_image = tf.image.central_crop(our_image, 0.5)\n",
        "print (new_image.shape)\n",
        "show(our_image, new_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9BJtI0ZjBR0"
      },
      "source": [
        "Crop to a bounding box:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR87xXD-jBYW"
      },
      "source": [
        "new_image = tf.image.crop_to_bounding_box(\n",
        "    our_image, 10, 10, 120, 120)\n",
        "print (new_image.shape)\n",
        "show(our_image, new_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzOPc4qk2a_o"
      },
      "source": [
        "## Randomly Flip Image Left to Right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y2cHFUuHgoY"
      },
      "source": [
        "Since the transformation is random, the image isn't always flipped:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrpNUal-EEjE"
      },
      "source": [
        "show_images(batch_images, indx, tf.image.random_flip_left_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8mH_ZT25_SG"
      },
      "source": [
        "## Randomly Flip Image Up to Down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Sth8_QHtO7"
      },
      "source": [
        "Since the transformation is random, the image isn't always flipped:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHB7b81d81MF"
      },
      "source": [
        "show_images(batch_images, indx, tf.image.random_flip_up_down)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y73-jUTg6IYz"
      },
      "source": [
        "## Flip Image Up to Down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQd11IcpH2xc"
      },
      "source": [
        "The image is always flipped:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuBV8Aq8_AxA"
      },
      "source": [
        "show(our_image, tf.image.flip_up_down(our_image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPMjEkNz62J-"
      },
      "source": [
        "## Rotate Image 90 Degrees\n",
        "\n",
        "Each **k** value rotates the image 90 degrees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN7xX61qH7eS"
      },
      "source": [
        "Rotate 90 degrees:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXZ_K0OMbd2_"
      },
      "source": [
        "show(our_image, tf.image.rot90(our_image, k=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U03Ckr_PH_Y6"
      },
      "source": [
        "Rotate 180 degrees:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmkkH-KT7CBN"
      },
      "source": [
        "show(our_image, tf.image.rot90(our_image, k=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdyYdf2k9a8Q"
      },
      "source": [
        "Rotate 270 degrees:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsnEqLxt9bDW"
      },
      "source": [
        "show(our_image, tf.image.rot90(our_image, k=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrVcXtgX-UM6"
      },
      "source": [
        "Rotate 360 degrees:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsDLnCw3-USA"
      },
      "source": [
        "show(our_image, tf.image.rot90(our_image, k=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds1K9WXv-bEy"
      },
      "source": [
        "We're back where we started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61r5PHkkehTJ"
      },
      "source": [
        "## Adjust Gamma\n",
        "\n",
        "**Gamma encoding** can be thought of as the intensity of an image. It is used to optimize the usage of bits when encoding an image by taking advantage of the non-linear manner that humans perceive light and color. The human perception of brightness (lightness) under common illumination conditions (neither pitch black nor blindingly bright) follows an approximate power function with greater sensitivity to relative differences between darker tones than between lighter tones.\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://en.wikipedia.org/wiki/Gamma_correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DbBrh62IDec"
      },
      "source": [
        "Adjust with gamma encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGRmYpKnfoze"
      },
      "source": [
        "new_image = tf.image.adjust_gamma(\n",
        "    our_image, gamma=0.75, gain=1.5)\n",
        "new_image = np.clip(new_image, 0, 1)\n",
        "show(our_image, new_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo4Z-1PzBuDk"
      },
      "source": [
        "Adjust gamma for brightness. For gamma less than 1, image is brighter. For gamma greater than 1, image is darker. Intensity is controlled by gain. Apply NumPy clip function to ensure that pixel values are still in between [0, 1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E24J4jE9Htc"
      },
      "source": [
        "## Adjust Contrast\n",
        "\n",
        "**Contrast** in image processing is the difference in luminance (or color) that makes an object distinguishable. It is determined by the difference in the color and brightness of the object and other objects within the same field of view."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLUIPRqhEGNw"
      },
      "source": [
        "Fixed contrast:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOKUzdeagjgQ"
      },
      "source": [
        "new_image = tf.image.adjust_contrast(\n",
        "    our_image, contrast_factor=1.8)\n",
        "new_image = np.clip(new_image, 0, 1)\n",
        "show(our_image, new_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GngRZvyuDdiK"
      },
      "source": [
        "Adjust contrast_factor for more or less luminance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip--o2usKQFP"
      },
      "source": [
        "Random contrast:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Deb5SzRyCtP0"
      },
      "source": [
        "show_images(batch_images, indx, tf.image.random_contrast,\n",
        "            0.75, 2.9, b=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyCf6uoz9gPL"
      },
      "source": [
        "## Adjust Brightness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYyz7EoaEhpx"
      },
      "source": [
        "Fixed brightness:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpe7BrEb9mQ8"
      },
      "source": [
        "new_image = tf.image.adjust_brightness(our_image, .25)\n",
        "new_image = np.clip(new_image, 0, 1)\n",
        "show(our_image, new_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5NZ1a1Eknh"
      },
      "source": [
        "Random brightness:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bWXdaiRANRm"
      },
      "source": [
        "show_images(batch_images, indx, tf.image.random_brightness,\n",
        "            0.25, b=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-KQA9Ug-SNL"
      },
      "source": [
        "## Adjust Saturation\n",
        "\n",
        "**Saturation** in image processing is the depth or intensity of color present within an image. The more saturated an image, the more colorful and vibrant it appears. Less color saturation makes an image appear subdued or muted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISCixYKdFDX9"
      },
      "source": [
        "Fixed saturation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l53pmN2Cfo_V"
      },
      "source": [
        "show(our_image, tf.image.adjust_saturation(our_image, 3.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB1-qlLeFFfJ"
      },
      "source": [
        "Random saturation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCgpoxSZEMNs"
      },
      "source": [
        "show_images(batch_images, indx, tf.image.random_saturation,\n",
        "            0.3, 3.5, b=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP0DKCMqTRBR"
      },
      "source": [
        "## Adjust Hue\n",
        "\n",
        "**Hue** is the main indication of a RGB color. It is the value that tells us whether an object is red, green or blue. In contrast, saturation is the perceived intensity. So saturation is how colorful the object looks, while hue is the actual color."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWjmJy2mT-wl"
      },
      "source": [
        "Fixed hue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X83VE5EkT-3F"
      },
      "source": [
        "show(our_image, tf.image.adjust_hue(our_image, 0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax5ZoklAT_Ly"
      },
      "source": [
        "Random hue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHjLKfM9TRJq"
      },
      "source": [
        "show_images(batch_images, indx, tf.image.random_hue, 0.2, b=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CovgUYbIIk3f"
      },
      "source": [
        "## Create an Augmentation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUY1SIgUI3cK"
      },
      "source": [
        "Randomly flip images from left to right apply a saturation operation to images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u50Hzt7aHttT"
      },
      "source": [
        "def augment(image, label):\n",
        "  img = tf.image.random_flip_left_right(image)\n",
        "  final_image = tf.image.random_saturation(img, 0, 2)\n",
        "  return (final_image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9YEDcOJTI-1"
      },
      "source": [
        "## Display an Augmented Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsrthxCGJCNi"
      },
      "source": [
        "Here is what happens when the **augment** function is applied to the same image several times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSyrhIj5SE0e"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  image, _ = augment(our_image, labels[0])\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb4ShkeAItnB"
      },
      "source": [
        "## Build the Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABfpj2QEJKEZ"
      },
      "source": [
        "Build a pipeline with train and test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGBWFGiTJ-CW"
      },
      "source": [
        "SHUFFLE_SIZE = 10000\n",
        "\n",
        "train1 = train_ds.map(scale, num_parallel_calls=4)\n",
        "train2 = train1.map(augment, num_parallel_calls=4)\n",
        "train_da = train2.shuffle(SHUFFLE_SIZE).cache().prefetch(1)\n",
        "test_da = test_ds.map(scale).cache().prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p4Icy4xJW61"
      },
      "source": [
        "Use **num_parallel** parameter for better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD8kWEhNIvtr"
      },
      "source": [
        "## Clear Previous Models and Generate Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFvk44xJJfYJ"
      },
      "source": [
        "Clear previous models and seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdVd0rHuZmiE"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV0MMo2zIynE"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YepzcpH4J8Ji"
      },
      "source": [
        "Create a multi-layer CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh4G2yXwUg_q"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  Conv2D(32, 3, activation='relu',\n",
        "         input_shape=[180, 180, 3]),\n",
        "  MaxPooling2D(),\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPooling2D(),\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPooling2D(),\n",
        "  Flatten(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dropout(0.5),\n",
        "  Dense(num)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSfwpnSTI0dz"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlNjgwzsKEDL"
      },
      "source": [
        "Compile with SparseCategoricalCrossentropy(from_logits=True):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDPcZTlNUhCO"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bawEhjBfI2yr"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioBCdo4OKJXT"
      },
      "source": [
        "Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kha64lWQUhEp"
      },
      "source": [
        "history = model.fit(\n",
        "    train_da,\n",
        "    validation_data=test_da,\n",
        "    epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELc0zEAO3t4Q"
      },
      "source": [
        "# Data Augmentation with ImageGenerator\n",
        "\n",
        "So far, we have augmented images in two ways. We utilized Keras preprocessing layers and applied TensorFlow operations directly on images to augment. Both methods build a tf.data pipeline to model the augmented dataset.\n",
        "\n",
        "An alternative is to use the ImageGenerator class. The ImageGenerator class makes it easy to load images from disk and augment them in various ways.\n",
        "We can shift, rotate, rescale, flip horizontally or vertically, shear or apply transformation functions to images. Although ImageGenerator is very convenient for simple projects, building a tf.data pipeline is more conducive to complex projects because it can read images in parallel from any source (not just a local disk), manipulate the dataset in any manner, and preprocessing functions based on tf.image operations can be used in the tf.data pipeline and in the model deployed to production.\n",
        "\n",
        "\n",
        "Resource:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkjoIxGWDZLY"
      },
      "source": [
        "## Use ImageDataGenerator to Process Flowers Data\n",
        "\n",
        "Load data directly from the flowers directory into train and test splits by utilizing dictionaries. The first dictionary provides scaling and splitting information to the ImageDataGenerator class. The second dictionary provides target and batch information to the class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGUo2Lj-RYgj"
      },
      "source": [
        "Import the appropriate library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsnvcwXcQ2ej"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image\\\n",
        "  import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r2RiBSAR0tN"
      },
      "source": [
        "Create a dictionary to scale and split data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNT6x_H1E0gu"
      },
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Qhl-m7M1Pr"
      },
      "source": [
        "Split is 81/19."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJPlDe8IRmaO"
      },
      "source": [
        "Create a dictionary to resize, batch, and interpolate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIfs8oT0E_Tv"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (180, 180)\n",
        "\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       interpolation='bilinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySPa55aTFbVf"
      },
      "source": [
        "### Create Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaJi4cpnKj2P"
      },
      "source": [
        "Create the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40u00i81Fba2"
      },
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.\\\n",
        "  ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset='validation', shuffle=False,\n",
        "    **dataflow_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4jZKVMkFqtl"
      },
      "source": [
        "### Create Train Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JurErpnKqz9"
      },
      "source": [
        "Create the train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfJ9LSH_Fqz4"
      },
      "source": [
        "train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset='training', shuffle=True,\n",
        "    **dataflow_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ1F2peCIJRs"
      },
      "source": [
        "### Clear Models and Generate Seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fFHY0ZyKtgT"
      },
      "source": [
        "Clear previous models and generate a seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_876iA9IJW9"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYwjQ7jaIUvf"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MalOJSWyKzuT"
      },
      "source": [
        "Create a multi-layer CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXf_H9_MIU1Q"
      },
      "source": [
        "model = Sequential([\n",
        "  Conv2D(filters=32, kernel_size=(5, 5), activation = 'relu',\n",
        "         input_shape=(180, 180, 3)),\n",
        "  MaxPooling2D(2),\n",
        "  Conv2D(64, (5, 5), activation='relu'),\n",
        "  MaxPooling2D(2),\n",
        "  Flatten(),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbWqUScyIcDw"
      },
      "source": [
        "### Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uejtk0xQLCzO"
      },
      "source": [
        "Compile with categorical_crossentropy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjfH7wcnIcQ0"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsMG4K1DI5PV"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_QvkfhKLHYV"
      },
      "source": [
        "Train for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwRWCq4YI5T6"
      },
      "source": [
        "history = model.fit(train_generator, batch_size=BATCH_SIZE,\n",
        "                    epochs=5, validation_data=valid_generator,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OpgPtSQKHA7"
      },
      "source": [
        "## Use ImageDataGenerator to Augment Train Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW_lXj74LSCH"
      },
      "source": [
        "Augment with **tf.keras.preprocessing.image.ImageDataGenerator**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lcj__RuKHK3"
      },
      "source": [
        "aug_train_datagen = tf.keras.preprocessing.\\\n",
        "  image.ImageDataGenerator(\n",
        "      rotation_range=40, horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ50-sEfKHQE"
      },
      "source": [
        "Create train set with data augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Q4fQEAKHVV"
      },
      "source": [
        "aug_train_generator = aug_train_datagen.flow_from_directory(\n",
        "    data_dir, subset='training', shuffle=True, **dataflow_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5dOConouFtD"
      },
      "source": [
        "Only augment train data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rtO6bFBKHaA"
      },
      "source": [
        "Clear model and generate seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCCrWzOKKHiv"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc8AB6iiKiv-"
      },
      "source": [
        "Recompile model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqgvVK1sKi1V"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsvEI_zFKmUI"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTxj1nz7KmZ_"
      },
      "source": [
        "history = model.fit(aug_train_generator, batch_size=BATCH_SIZE,\n",
        "                    epochs=5, validation_data=valid_generator,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3v9IpJkGQog"
      },
      "source": [
        "### Inspect the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGqAxaA6GaEw"
      },
      "source": [
        "Grab a batch from the original training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8XtL1suGQuQ"
      },
      "source": [
        "data_list = []\n",
        "batch_index, end_index = 0, 1\n",
        "while batch_index <= train_generator.batch_index:\n",
        "  if batch_index < end_index:\n",
        "    data = train_generator.next()\n",
        "    data_list.append(data[0])\n",
        "    batch_index = batch_index + 1\n",
        "  else: break\n",
        "original = np.asarray(data_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvisbdsMGQ2d"
      },
      "source": [
        "Inspect the shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oNjq0iqGQ7s"
      },
      "source": [
        "original[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwaG9QTeGRA-"
      },
      "source": [
        "Grab a batch from the augmented training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJUOZQk0GRGH"
      },
      "source": [
        "data_list = []\n",
        "batch_index, end_index = 0, 1\n",
        "while batch_index <= aug_train_generator.batch_index:\n",
        "  if batch_index < end_index:\n",
        "    data = aug_train_generator.next()\n",
        "    data_list.append(data[0])\n",
        "    batch_index = batch_index + 1\n",
        "  else: break\n",
        "augmented = np.asarray(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WXBCOE5Gqze"
      },
      "source": [
        "Inspect the shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuK-zr-ZGq5B"
      },
      "source": [
        "augmented[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIQZBYG6Gq9s"
      },
      "source": [
        "Visualize a training image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxBpa_x7G3bO"
      },
      "source": [
        "train_image = original[0][0]\n",
        "\n",
        "plt.imshow(train_image)\n",
        "plt.axis('off')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epCTkaoHGrCq"
      },
      "source": [
        "Visualize several training images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD6ZAK4TG_jn"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images in original:\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwqXzQT9G992"
      },
      "source": [
        "Visualize an augmented image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqMEdV9WG-GQ"
      },
      "source": [
        "aug_train_image = augmented[0][0]\n",
        "\n",
        "plt.imshow(aug_train_image)\n",
        "plt.axis('off')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzYUL3cJG-Mm"
      },
      "source": [
        "Visualize several augmented images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNEWctqbG-bP"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images in augmented:\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kno14pwHXqN"
      },
      "source": [
        "The original training images look like normal flower images. However, we see that the augmented images are definitely transformed."
      ]
    }
  ]
}